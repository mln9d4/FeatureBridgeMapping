{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d12b707",
   "metadata": {},
   "source": [
    "# DDPM forward and reverse process implementation\n",
    "Paper: https://arxiv.org/abs/2006.11239\n",
    "\n",
    "## Forward Process\n",
    "Fowrad process adss noise to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2908a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from data.dataset import BEVFeaturesDataset, PaddDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import wandb\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d21e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c3b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from inspect import isfunction\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128,\n",
    "        eps=1e-5\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn, eps=eps))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True, eps=eps),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False, eps=eps)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn, eps=eps))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups, eps=eps)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "\n",
    "# PositionalEncoding Source： https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype, device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat([torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim, eps=eps),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups, eps=eps)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout, eps=eps)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel, eps=eps)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\"bnchw, bncyx -> bnhwyx\", query, key).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout, eps=eps)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups, eps=eps)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d22a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, var\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-6, linear_end=1e-2, cosine_s=8e-3):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that is a function of the number of diffusion steps.\n",
    "    Return:\n",
    "        betas: a numpy array of shape (n_timestep,) that defines the beta schedule\n",
    "    \"\"\"\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return torch.from_numpy(betas) if betas.type == np.ndarray else betas\n",
    "\n",
    "\n",
    "class DenoiseDiffusion(nn.Module):\n",
    "    def __init__(self, eps_model, beta_schedule, loss_fn=nn.L1Loss()):\n",
    "        super().__init__()\n",
    "        # Parameters for training\n",
    "        self.loss_fn = loss_fn\n",
    "        self.eps_model = eps_model\n",
    "        self.beta_schedule = beta_schedule\n",
    "\n",
    "\n",
    "        # Parameters for diffusion process         \n",
    "    def set_new_noise_schedule(self, device=torch.device('cuda'), phase='train'):\n",
    "        self.n_steps = self.beta_schedule[phase]['n_timestep']\n",
    "        to_torch = partial(torch.as_tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(**self.beta_schedule[phase])\n",
    "        # self.betas = beta.type(dtype=torch.float32).to(self.eps_model.device)\n",
    "        alphas = 1. - betas\n",
    "        gammas = torch.cumprod(alphas, dim=0)\n",
    "        sigmas = torch.sqrt(1.0 - torch.pow(alphas, 2))\n",
    "        lambdas = torch.log(alphas / sigmas)\n",
    "\n",
    "        self.register_buffer(\"betas\", to_torch(betas))\n",
    "        self.register_buffer(\"alphas\", to_torch(alphas))\n",
    "        self.register_buffer(\"gammas\", to_torch(gammas))\n",
    "        self.register_buffer(\"sigmas\", to_torch(sigmas))\n",
    "        self.register_buffer(\"lambdas\", to_torch(lambdas))\n",
    "\n",
    "\n",
    "    # def to(self, device):\n",
    "        # self.eps_model = self.eps_model.to(device)\n",
    "\n",
    "    def gather(self, tensor, t):\n",
    "        \"\"\"\n",
    "        Gather the values of x at the time steps t.\n",
    "        Makes it compatible with the shape of x0, which is (B, C, H, W).\n",
    "        Args:\n",
    "            tensor: a tensor of shape (n_steps,)\n",
    "            t: a tensor of shape (B,)\n",
    "        Return:\n",
    "            a tensor of shape (B, 1, 1, 1) that contains the values of x at the time steps t\n",
    "        \"\"\"\n",
    "        t = tensor.gather(-1, t)\n",
    "        return t.reshape(-1, 1, 1, 1)\n",
    "    \n",
    "        # We need a function that samples the batch \n",
    "    def q_sample(self, y0, sample_gammas, noise=None):\n",
    "        \"\"\"\n",
    "        Sample from q(yt|y0), reading same as sample xt at step t given x0.\n",
    "        Other implementations also use function q_xt_x0 first but we can directly implement it here.\n",
    "        Args:\n",
    "            y0: the original data, shape (B, C, H, W)\n",
    "            sample_gammas: the gamma values for sampling, shape (B,)\n",
    "            noise: the noise, shape (B, C, H, W)\n",
    "        Return:\n",
    "            yt: the noisy data at time step t, shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        eps = torch.randn_like(y0, device=y0.device) if noise is None else noise\n",
    "        \n",
    "        return (\n",
    "            torch.sqrt(sample_gammas) * y0 + torch.sqrt(1 - sample_gammas) * eps\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, y0, y_cond=None):\n",
    "        \"\"\"\n",
    "        Algorithm 1 in Denoising Diffusion Probalisitic Models\n",
    "\n",
    "        Args:\n",
    "            y0: the original data, shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        b, *_ = y0.shape\n",
    "\n",
    "        t = torch.randint(1, self.n_steps, (b,), device=y0.device, dtype=torch.long)\n",
    "        # Select a random gamma for each sample in the batch, which is between gamma_t and gamma_t-1 of generated timesteps t. This is to make the training more stable and avoid overfitting to specific timesteps.\n",
    "        gamma_t1 = self.gather(self.gammas, t - 1)\n",
    "        gamma_t2 = self.gather(self.gammas, t)\n",
    "        sample_gammas = (gamma_t2 - gamma_t1) * torch.rand((b, 1, 1, 1), device=y0.device) + gamma_t1\n",
    "        sample_gammas = sample_gammas\n",
    "\n",
    "        # Create the noise to compare it to the predicted noise, which is used for training the model. This is the noise added to the original data to get the noisy data at time step t.\n",
    "        noise = torch.randn_like(y0, device=y0.device)\n",
    "        y_noisy = self.q_sample(y0, sample_gammas, noise=noise)\n",
    "\n",
    "        noise_hat = self.eps_model(torch.cat([y_noisy, y_cond], dim=1) if y_cond is not None else y_noisy, sample_gammas)\n",
    "\n",
    "        loss = self.loss_fn(noise_hat, noise)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    # Samplers\n",
    "\n",
    "    @torch.no_grad()\n",
    "    #TODO implement y_cond and remove n_samples\n",
    "    def ddpm_sampler(self, y_cond=None, sample_inter=10, clip_denoised=True):\n",
    "        \"\"\"\n",
    "        https://arxiv.org/pdf/2006.11239\n",
    "        Implementation of algorithm 2. However, to keep sampling stable we calculate the start from noise, clamp it and use the posterior of equation 7 to calculate y_t-1.\n",
    "        We use equation 15 to calculate y_0 (start from noise), then clamp it. Then we use equation 7 to calculate y_t-1 = mean + sigma * z\n",
    "        \"\"\"\n",
    "        y = torch.randn_like(y_cond, device=y_cond.device)\n",
    "        ret_arr = y.clone()\n",
    "        for i in tqdm(reversed(range(self.n_steps)), desc='DDPM sampler', total=self.n_steps):\n",
    "            z = torch.randn_like(y) if i > 1 else torch.zeros_like(y)   \n",
    "            t_tensor = torch.full((y_cond.shape[0],), i, device=y_cond.device, dtype=torch.long)\n",
    "\n",
    "            gamma_t = self.gather(self.gammas, t_tensor)\n",
    "            gamma_t_prev = self.gather(self.gammas, t_tensor - 1) if i > 0 else torch.ones_like(gamma_t)\n",
    "            beta_t = self.gather(self.betas, t_tensor)\n",
    "            alpha_t = self.gather(self.alphas, t_tensor)\n",
    "\n",
    "            y_0_tilde = (y - torch.sqrt(1-gamma_t)*self.eps_model(torch.cat([y, y_cond], dim=1) if y_cond is not None else y, gamma_t)) / torch.sqrt(gamma_t) # predict start\n",
    "\n",
    "            if clip_denoised:\n",
    "                y_0_tilde = torch.clamp(y_0_tilde, -1., 1.)\n",
    "\n",
    "            # eta = (y - torch.sqrt(alpha_t)*y_0_tilde) / torch.sqrt(1-alpha_t)\n",
    "\n",
    "            # Calculate posterior mean and variance\n",
    "            mean = (torch.sqrt(gamma_t_prev) * beta_t * y_0_tilde) / (1 - gamma_t) + (torch.sqrt(alpha_t) * (1 - gamma_t_prev) * y) / (1 - gamma_t)\n",
    "\n",
    "            sigma = (1 - gamma_t_prev) * beta_t / (1 - gamma_t)\n",
    "\n",
    "            y = mean + sigma * z\n",
    "\n",
    "            if i % sample_inter == 0:\n",
    "                ret_arr = torch.cat((ret_arr, y), dim=0)\n",
    "\n",
    "        return y, ret_arr\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_sampler(self, y_cond=None, noise=None, sample_inter=10, steps=50, clip_denoised=True, eta=0.0):\n",
    "        \"\"\"\n",
    "        DDIM sampler from https://arxiv.org/abs/2010.02502\n",
    "        With eta=0, it becomes a deterministic sampler, which is the one we will use in this implementation. With eta>0, it becomes a stochastic sampler, which is similar to the DDPM sampler but with different noise scale. \n",
    "        \"\"\"\n",
    "        y = torch.randn_like(y_cond, device=y_cond.device) if noise is None else noise\n",
    "        ret_arr = y.clone()\n",
    "        step_size = self.n_steps // steps\n",
    "\n",
    "        for i in tqdm(range(steps), desc='DDIM sampling loop timestep', total=steps):\n",
    "            t = self.n_steps - i * step_size\n",
    "            t_tensor = torch.full((y_cond.shape[0],), t, dtype=torch.long, device=y_cond.device)\n",
    "\n",
    "            gamma = self.gather(self.gammas, t_tensor - 1)\n",
    "            \n",
    "            # Make sure that when t_tensor - step_size - 1 is negative, we use gamma_prev = 1, which means that we are at the final step and we should not add any noise.\n",
    "            gamma_prev = self.gather(self.gammas, torch.clamp(t_tensor - step_size - 1, min=0)) if (t_tensor - step_size - 1 >= 0).any() else torch.ones_like(gamma)\n",
    "            noise_pred = self.eps_model(torch.cat([y, y_cond], dim=1) if y_cond is not None else y, gamma)\n",
    "\n",
    "            y0_pred = (y - torch.sqrt(1 - gamma) * noise_pred) / torch.sqrt(gamma)\n",
    "            \n",
    "            # Clamp prediction to stablize sampling\n",
    "            if clip_denoised:\n",
    "                y0_pred = torch.clamp(y0_pred, -1., 1.)\n",
    "\n",
    "            sigma_t = eta * torch.sqrt((1 - gamma_prev) / (1 - gamma)) * torch.sqrt(1-gamma / gamma_prev)\n",
    "\n",
    "            dir_yt = torch.sqrt(1 - gamma_prev - torch.pow(sigma_t, 2)) * noise_pred\n",
    "            \n",
    "            \n",
    "            y = torch.sqrt(gamma_prev) * y0_pred + dir_yt + sigma_t * torch.randn_like(y)\n",
    "\n",
    "        return y, ret_arr\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def dpm_solver_multi_step_sampler(self, y_cond=None, sample_inter=10, steps=10, clip_denoised=True):\n",
    "        \"\"\"\n",
    "        Implement multistep from https://arxiv.org/pdf/2211.01095\n",
    "        \"\"\"\n",
    "        step_size = self.n_steps // steps\n",
    "\n",
    "\n",
    "        yT = torch.randn_like(y_cond, device=y_cond.device)\n",
    "        ret_arr = yT.clone()\n",
    "\n",
    "        ytilde = yT\n",
    "\n",
    "\n",
    "        t_0 = torch.full((y_cond.shape[0],), self.n_steps - 1, device=y_cond.device, dtype=torch.long)\n",
    "        t_1 = torch.full((y_cond.shape[0],), self.n_steps - step_size - 1, device=y_cond.device, dtype=torch.long)\n",
    "        t_2 = torch.full((y_cond.shape[0],), self.n_steps - 2 * step_size - 1, device=y_cond.device, dtype=torch.long)\n",
    "        # print(self.lambdas.shape)\n",
    "        # print(t_1)\n",
    "        # print(t_0)\n",
    "        h_i_prev = self.gather(self.lambdas, t_1) - self.gather(self.lambdas, t_0)\n",
    "\n",
    "        # Buffer P and Q for multi_step sampling. P = -2 and Q = -1 in timestepe space, which means that they are the data prediction at t_i-2 and t_i-1 respectively. We will update them in each step and use them to calculate the data prediction at t_i.\n",
    "        P = self.data_prediction(ytilde, y_cond=y_cond, t=t_0) # y_theta_0\n",
    "        if clip_denoised:\n",
    "            P = torch.clamp(P, -1., 1.)\n",
    "        y_tilde = (self.gather(self.sigmas, t_1)/self.gather(self.sigmas, t_0)) * ytilde - self.gather(self.alphas, t_1) * (torch.exp(-h_i_prev) - 1) * P\n",
    "        Q = self.data_prediction(y_tilde, y_cond=y_cond, t=t_1) # y_theta_2\n",
    "        if clip_denoised:\n",
    "            Q = torch.clamp(Q, -1, 1.)\n",
    "        \n",
    "\n",
    "        for i in tqdm((range(2, steps)), desc='DPM-Solver++(2M) sampler', initial=2, total=steps):\n",
    "            t_cur = self.n_steps - i * step_size - 1\n",
    "            t_prev = self.n_steps - (i - 1) * step_size - 1\n",
    "\n",
    "            t_prev_tensor = torch.full((y_cond.shape[0],), t_prev, device=y_cond.device, dtype=torch.long)\n",
    "            t_cur_tensor = torch.full((y_cond.shape[0],), t_cur, device=y_cond.device, dtype=torch.long)\n",
    "\n",
    "            h_i_cur = self.gather(self.lambdas, t_cur_tensor) - self.gather(self.lambdas, t_prev_tensor)\n",
    "            r_i = h_i_prev / h_i_cur\n",
    "\n",
    "            D_i = (1 + 1 / (2 * r_i)) * Q - 1 / (2 * r_i) * P\n",
    "\n",
    "            y_tilde = (self.gather(self.sigmas, t_cur_tensor) / self.gather(self.sigmas, t_prev_tensor)) * y_tilde - self.gather(self.alphas, t_cur_tensor) * (torch.exp(-h_i_cur) - 1) * D_i\n",
    "            \n",
    "            h_i_prev = h_i_cur\n",
    "            P = Q.clone()\n",
    "            if i < self.n_steps:\n",
    "                Q = self.data_prediction(y_tilde, y_cond=y_cond, t=t_cur_tensor)\n",
    "                if clip_denoised:\n",
    "                    Q = torch.clamp(Q, -1., 1.)\n",
    "\n",
    "            if i % sample_inter == 0:\n",
    "                ret_arr = torch.cat((ret_arr, y_tilde), dim=0)\n",
    "\n",
    "        return y_tilde, ret_arr\n",
    "    \n",
    "    def data_prediction(self, yt, y_cond=None, t=None):\n",
    "        gamma = self.gather(self.gammas, t).to(yt.device)\n",
    "        noise_pred = self.eps_model(torch.cat([yt, y_cond], dim=1) if y_cond is not None else yt, gamma)\n",
    "        y0_hat = (yt - torch.sqrt(1 - gamma) * noise_pred) / torch.sqrt(gamma)\n",
    "\n",
    "        return y0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ad3ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_schedule = dict(\n",
    "    train=dict(\n",
    "        schedule='cosine',\n",
    "        n_timestep=2000,\n",
    "        cosine_s=8e-3,\n",
    "    ),\n",
    "    test=dict(\n",
    "        schedule='linear',\n",
    "        n_timestep=1000,\n",
    "        linear_start=1e-5,\n",
    "        linear_end=1e-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_config = dict(\n",
    "    in_channel=512,\n",
    "    out_channel=256,\n",
    "    inner_channel=128,\n",
    "    norm_groups=32,\n",
    "    channel_mults=(1, 2, 4, 8),\n",
    "    attn_res=(25,),\n",
    "    res_blocks=2,\n",
    "    dropout=0,\n",
    "    with_noise_level_emb=True,\n",
    "    image_size=200,\n",
    "    eps=1e-5\n",
    ")\n",
    "\n",
    "hyperparameters = dict(\n",
    "    model_config=model_config,\n",
    "    beta_schedule=beta_schedule,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "Unet = UNet(**model_config)\n",
    "diffusion = DenoiseDiffusion(Unet, beta_schedule)\n",
    "diffusion.set_new_noise_schedule(phase='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b4be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDPM sampler:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDPM sampler:  78%|███████▊  | 1566/2000 [03:02<00:48,  9.03it/s]"
     ]
    }
   ],
   "source": [
    "diffusion.to('cuda')\n",
    "out, _ = diffusion.ddpm_sampler(y_cond=torch.randn(1, 256, 200, 200, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74bb0781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "UNet                                               [8, 256, 200, 200]        --\n",
       "├─Sequential: 1-1                                  [8, 1, 128]               --\n",
       "│    └─PositionalEncoding: 2-1                     [8, 1, 128]               --\n",
       "│    └─Linear: 2-2                                 [8, 1, 512]               66,048\n",
       "│    └─Swish: 2-3                                  [8, 1, 512]               --\n",
       "│    └─Linear: 2-4                                 [8, 1, 128]               65,664\n",
       "├─ModuleList: 1-2                                  --                        --\n",
       "│    └─Conv2d: 2-5                                 [8, 128, 200, 200]        589,952\n",
       "│    └─ResnetBlocWithAttn: 2-6                     [8, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-1                       [8, 128, 200, 200]        312,192\n",
       "│    └─ResnetBlocWithAttn: 2-7                     [8, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-2                       [8, 128, 200, 200]        312,192\n",
       "│    └─Downsample: 2-8                             [8, 128, 100, 100]        --\n",
       "│    │    └─Conv2d: 3-3                            [8, 128, 100, 100]        147,584\n",
       "│    └─ResnetBlocWithAttn: 2-9                     [8, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-4                       [8, 256, 100, 100]        952,064\n",
       "│    └─ResnetBlocWithAttn: 2-10                    [8, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-5                       [8, 256, 100, 100]        1,214,208\n",
       "│    └─Downsample: 2-11                            [8, 256, 50, 50]          --\n",
       "│    │    └─Conv2d: 3-6                            [8, 256, 50, 50]          590,080\n",
       "│    └─ResnetBlocWithAttn: 2-12                    [8, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-7                       [8, 512, 50, 50]          3,739,136\n",
       "│    └─ResnetBlocWithAttn: 2-13                    [8, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-8                       [8, 512, 50, 50]          4,787,712\n",
       "│    └─Downsample: 2-14                            [8, 512, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-9                            [8, 512, 25, 25]          2,359,808\n",
       "│    └─ResnetBlocWithAttn: 2-15                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-10                      [8, 1024, 25, 25]         14,818,304\n",
       "│    │    └─SelfAttention: 3-11                    [8, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-16                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-12                      [8, 1024, 25, 25]         19,012,608\n",
       "│    │    └─SelfAttention: 3-13                    [8, 1024, 25, 25]         4,197,376\n",
       "├─ModuleList: 1-3                                  --                        --\n",
       "│    └─ResnetBlocWithAttn: 2-17                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-14                      [8, 1024, 25, 25]         19,012,608\n",
       "│    │    └─SelfAttention: 3-15                    [8, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-18                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-16                      [8, 1024, 25, 25]         19,012,608\n",
       "├─ModuleList: 1-4                                  --                        --\n",
       "│    └─ResnetBlocWithAttn: 2-19                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-17                      [8, 1024, 25, 25]         30,550,016\n",
       "│    │    └─SelfAttention: 3-18                    [8, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-20                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-19                      [8, 1024, 25, 25]         30,550,016\n",
       "│    │    └─SelfAttention: 3-20                    [8, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-21                    [8, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-21                      [8, 1024, 25, 25]         25,306,112\n",
       "│    │    └─SelfAttention: 3-22                    [8, 1024, 25, 25]         4,197,376\n",
       "│    └─Upsample: 2-22                              [8, 1024, 50, 50]         --\n",
       "│    │    └─Upsample: 3-23                         [8, 1024, 50, 50]         --\n",
       "│    │    └─Conv2d: 3-24                           [8, 1024, 50, 50]         9,438,208\n",
       "│    └─ResnetBlocWithAttn: 2-23                    [8, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-25                      [8, 512, 50, 50]          10,295,296\n",
       "│    └─ResnetBlocWithAttn: 2-24                    [8, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-26                      [8, 512, 50, 50]          7,672,832\n",
       "│    └─ResnetBlocWithAttn: 2-25                    [8, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-27                      [8, 512, 50, 50]          6,361,600\n",
       "│    └─Upsample: 2-26                              [8, 512, 100, 100]        --\n",
       "│    │    └─Upsample: 3-28                         [8, 512, 100, 100]        --\n",
       "│    │    └─Conv2d: 3-29                           [8, 512, 100, 100]        2,359,808\n",
       "│    └─ResnetBlocWithAttn: 2-27                    [8, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-30                      [8, 256, 100, 100]        2,591,744\n",
       "│    └─ResnetBlocWithAttn: 2-28                    [8, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-31                      [8, 256, 100, 100]        1,935,872\n",
       "│    └─ResnetBlocWithAttn: 2-29                    [8, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-32                      [8, 256, 100, 100]        1,607,936\n",
       "│    └─Upsample: 2-30                              [8, 256, 200, 200]        --\n",
       "│    │    └─Upsample: 3-33                         [8, 256, 200, 200]        --\n",
       "│    │    └─Conv2d: 3-34                           [8, 256, 200, 200]        590,080\n",
       "│    └─ResnetBlocWithAttn: 2-31                    [8, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-35                      [8, 128, 200, 200]        656,896\n",
       "│    └─ResnetBlocWithAttn: 2-32                    [8, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-36                      [8, 128, 200, 200]        492,800\n",
       "│    └─ResnetBlocWithAttn: 2-33                    [8, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-37                      [8, 128, 200, 200]        492,800\n",
       "├─Block: 1-5                                       [8, 256, 200, 200]        --\n",
       "│    └─Sequential: 2-34                            [8, 256, 200, 200]        --\n",
       "│    │    └─GroupNorm: 3-38                        [8, 128, 200, 200]        256\n",
       "│    │    └─Swish: 3-39                            [8, 128, 200, 200]        --\n",
       "│    │    └─Identity: 3-40                         [8, 128, 200, 200]        --\n",
       "│    │    └─Conv2d: 3-41                           [8, 256, 200, 200]        295,168\n",
       "====================================================================================================\n",
       "Total params: 243,374,464\n",
       "Trainable params: 243,374,464\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 3.80\n",
       "====================================================================================================\n",
       "Input size (MB): 655.36\n",
       "Forward/backward pass size (MB): 20706.07\n",
       "Params size (MB): 973.50\n",
       "Estimated Total Size (MB): 22334.92\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(Unet, input_size=[(hyperparameters['batch_size'], model_config['in_channel'], model_config['image_size'], model_config['image_size']), (hyperparameters['batch_size'], 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb31013",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "square_size = 16\n",
    "tensor = torch.zeros(1, 1, size, size)\n",
    "start = (size - square_size) // 2\n",
    "end = start + square_size\n",
    "tensor[:, :, start:end, start:end] = 1.0\n",
    "\n",
    "samples = tensor.repeat(100, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion.set_new_noise_schedule(phase='test')\n",
    "sampled = diffusion.dpm_solver_multi_step_sampler(1, steps=50, clip_denoised=True)\n",
    "y, ret_arr = sampled\n",
    "print(y)\n",
    "print(f\"Max: {torch.amax(y)}, Min: {torch.amin(y)}\")\n",
    "plt.imshow(y.cpu().numpy()[0, 0], cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ceac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data():\n",
    "    # Load the saved data\n",
    "    dataset = BEVFeaturesDataset(root_dir='/home/mingdayang/FeatureBridgeMapping/data/bev_features', transform=None)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_splits(dataset, train_split=0.8):\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(train_split * len(dataset)), len(dataset) - int(train_split * len(dataset))])\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def make_loader(batch_size, dataset):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        # Let's check out what we've created\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "dataset = load_data()\n",
    "train_dataset, test_dataset = create_splits(dataset)\n",
    "train_loader = make_loader(hyperparameters['batch_size'], train_dataset)\n",
    "test_loader = make_loader(hyperparameters['batch_size'], test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af730afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmln9d4\u001b[0m (\u001b[33mmln9d4-tu-delft\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mingdayang/FeatureBridgeMapping/wandb/run-20260217_131236-qbg1j056</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test/runs/qbg1j056' target=\"_blank\">youthful-tree-30</a></strong> to <a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test' target=\"_blank\">https://wandb.ai/mln9d4-tu-delft/diffusion_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test/runs/qbg1j056' target=\"_blank\">https://wandb.ai/mln9d4-tu-delft/diffusion_test/runs/qbg1j056</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:   9%|▉         | 1/11 [00:02<00:21,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8441227078437805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  18%|█▊        | 2/11 [00:04<00:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8360666632652283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  27%|██▋       | 3/11 [00:05<00:15,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8235496282577515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  36%|███▋      | 4/11 [00:07<00:13,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8175937533378601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  45%|████▌     | 5/11 [00:09<00:11,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8118245601654053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8065184950828552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8035463690757751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  73%|███████▎  | 8/11 [00:15<00:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8023022413253784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  82%|████████▏ | 9/11 [00:17<00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8011170625686646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  91%|█████████ | 10/11 [00:20<00:02,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8000731468200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████| 11/11 [00:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7993554472923279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:   9%|▉         | 1/11 [00:01<00:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7987856268882751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  18%|█▊        | 2/11 [00:03<00:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7984997630119324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  27%|██▋       | 3/11 [00:05<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7984712719917297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  36%|███▋      | 4/11 [00:07<00:13,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7982845306396484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  45%|████▌     | 5/11 [00:09<00:11,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7976917028427124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.797479510307312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7973124384880066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  73%|███████▎  | 8/11 [00:14<00:05,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7970888614654541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  82%|████████▏ | 9/11 [00:18<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7966421842575073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  91%|█████████ | 10/11 [00:20<00:02,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7970740795135498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|██████████| 11/11 [00:22<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7967941761016846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:   9%|▉         | 1/11 [00:01<00:18,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.796898365020752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  18%|█▊        | 2/11 [00:03<00:17,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7962692975997925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  27%|██▋       | 3/11 [00:05<00:15,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7959099411964417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  36%|███▋      | 4/11 [00:07<00:13,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7960195541381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  45%|████▌     | 5/11 [00:09<00:11,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7965874075889587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.796532928943634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7959973812103271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7970651388168335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7953234910964966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  91%|█████████ | 10/11 [00:20<00:02,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7957515716552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|██████████| 11/11 [00:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7950561046600342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:   9%|▉         | 1/11 [00:01<00:19,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7952281832695007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  18%|█▊        | 2/11 [00:03<00:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7944297790527344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  27%|██▋       | 3/11 [00:05<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.794302225112915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7951439023017883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  45%|████▌     | 5/11 [00:09<00:11,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7937213778495789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.794418215751648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  64%|██████▎   | 7/11 [00:15<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7933404445648193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7926390767097473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7943829298019409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  91%|█████████ | 10/11 [00:21<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7937290668487549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7923153042793274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:   9%|▉         | 1/11 [00:01<00:18,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7924906611442566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  18%|█▊        | 2/11 [00:03<00:16,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7912731766700745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7920214533805847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.793274462223053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  45%|████▌     | 5/11 [00:09<00:11,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7902165651321411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  55%|█████▍    | 6/11 [00:13<00:13,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7904682159423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  64%|██████▎   | 7/11 [00:15<00:09,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7896623611450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7902094125747681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7881224155426025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  91%|█████████ | 10/11 [00:21<00:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7874919176101685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7898820638656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:   9%|▉         | 1/11 [00:01<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7864083647727966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  18%|█▊        | 2/11 [00:03<00:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7863025069236755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7857045531272888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  36%|███▋      | 4/11 [00:07<00:13,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.786055326461792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  45%|████▌     | 5/11 [00:11<00:16,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7828835844993591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  55%|█████▍    | 6/11 [00:13<00:12,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.783279299736023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  64%|██████▎   | 7/11 [00:15<00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7823695540428162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7796109318733215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7772848606109619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  91%|█████████ | 10/11 [00:21<00:02,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7803148031234741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7775654196739197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:   9%|▉         | 1/11 [00:01<00:19,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7787734270095825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  18%|█▊        | 2/11 [00:03<00:17,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7769889235496521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  27%|██▋       | 3/11 [00:05<00:15,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7741247415542603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  36%|███▋      | 4/11 [00:09<00:18,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7732566595077515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  45%|████▌     | 5/11 [00:11<00:14,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.778141975402832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  55%|█████▍    | 6/11 [00:13<00:11,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7739723324775696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.770585834980011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7681195139884949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7769440412521362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  91%|█████████ | 10/11 [00:21<00:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.765667736530304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300: 100%|██████████| 11/11 [00:22<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7651867866516113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:   9%|▉         | 1/11 [00:01<00:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7700921893119812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  18%|█▊        | 2/11 [00:03<00:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7636364698410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  27%|██▋       | 3/11 [00:08<00:23,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7721006870269775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  36%|███▋      | 4/11 [00:10<00:18,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7659868597984314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  45%|████▌     | 5/11 [00:11<00:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.759876012802124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7772618532180786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.773729681968689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7673633098602295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7566608190536499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  91%|█████████ | 10/11 [00:21<00:02,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7590855360031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300: 100%|██████████| 11/11 [00:23<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7674962878227234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:   9%|▉         | 1/11 [00:01<00:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7566249370574951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7626208662986755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  27%|██▋       | 3/11 [00:08<00:21,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7545785307884216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  36%|███▋      | 4/11 [00:10<00:16,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7577865719795227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  45%|████▌     | 5/11 [00:11<00:13,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.750921368598938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7588316202163696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7528528571128845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  73%|███████▎  | 8/11 [00:17<00:05,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7548947930335999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  82%|████████▏ | 9/11 [00:19<00:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7560904026031494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  91%|█████████ | 10/11 [00:21<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.753282368183136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7482677698135376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:   9%|▉         | 1/11 [00:03<00:37,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7634565234184265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  18%|█▊        | 2/11 [00:05<00:24,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7477062344551086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  27%|██▋       | 3/11 [00:07<00:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7437124848365784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  36%|███▋      | 4/11 [00:09<00:15,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7516869902610779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  45%|████▌     | 5/11 [00:11<00:12,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7434467673301697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  55%|█████▍    | 6/11 [00:13<00:09,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7491068840026855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  64%|██████▎   | 7/11 [00:15<00:07,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.747697114944458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  73%|███████▎  | 8/11 [00:17<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7410244345664978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  82%|████████▏ | 9/11 [00:18<00:03,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7403913140296936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  91%|█████████ | 10/11 [00:20<00:01,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.748776912689209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.740047037601471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:   9%|▉         | 1/11 [00:01<00:18,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7390502691268921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  18%|█▊        | 2/11 [00:03<00:17,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7471584677696228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  27%|██▋       | 3/11 [00:05<00:15,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7475237250328064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7471215128898621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  45%|████▌     | 5/11 [00:09<00:11,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7548812627792358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7377633452415466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7387232780456543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  73%|███████▎  | 8/11 [00:15<00:05,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7351105809211731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  82%|████████▏ | 9/11 [00:17<00:03,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.737082839012146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  91%|█████████ | 10/11 [00:21<00:02,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7460026144981384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7400280833244324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:   9%|▉         | 1/11 [00:01<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7423542141914368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  18%|█▊        | 2/11 [00:03<00:17,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7399508953094482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7402819991111755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  36%|███▋      | 4/11 [00:07<00:13,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7449744939804077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  45%|████▌     | 5/11 [00:09<00:11,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7430785298347473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7369444370269775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7312026023864746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  73%|███████▎  | 8/11 [00:15<00:05,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7300217747688293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  82%|████████▏ | 9/11 [00:19<00:05,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7430335879325867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  91%|█████████ | 10/11 [00:21<00:02,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7342144250869751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7294101119041443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:   9%|▉         | 1/11 [00:01<00:19,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.739787757396698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  18%|█▊        | 2/11 [00:03<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7302761077880859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  27%|██▋       | 3/11 [00:05<00:15,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7332197427749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  36%|███▋      | 4/11 [00:07<00:13,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7367726564407349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  45%|████▌     | 5/11 [00:09<00:11,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7410221695899963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7465898394584656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7376255393028259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358484268188477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.747573971748352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  91%|█████████ | 10/11 [00:21<00:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358379364013672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300: 100%|██████████| 11/11 [00:22<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7365199327468872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:   9%|▉         | 1/11 [00:02<00:20,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.743800938129425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  18%|█▊        | 2/11 [00:03<00:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7272002100944519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  27%|██▋       | 3/11 [00:05<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.740547776222229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7315204739570618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  45%|████▌     | 5/11 [00:09<00:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7431174516677856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7307971715927124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  64%|██████▎   | 7/11 [00:15<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7271736860275269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7256747484207153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7245981693267822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  91%|█████████ | 10/11 [00:21<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358826994895935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7303423285484314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:   9%|▉         | 1/11 [00:01<00:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7311898469924927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  18%|█▊        | 2/11 [00:03<00:17,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7385170459747314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7260569334030151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  36%|███▋      | 4/11 [00:07<00:13,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7328760027885437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  45%|████▌     | 5/11 [00:09<00:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7343663573265076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  55%|█████▍    | 6/11 [00:13<00:12,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358404994010925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  64%|██████▎   | 7/11 [00:15<00:09,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7243000268936157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7285226583480835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7240411639213562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  91%|█████████ | 10/11 [00:21<00:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7221397161483765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300: 100%|██████████| 11/11 [00:22<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7195029854774475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:   9%|▉         | 1/11 [00:01<00:19,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7199113965034485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  18%|█▊        | 2/11 [00:03<00:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7204291820526123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  27%|██▋       | 3/11 [00:05<00:14,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7197888493537903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  36%|███▋      | 4/11 [00:07<00:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7212901711463928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  45%|████▌     | 5/11 [00:11<00:15,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7377653121948242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  55%|█████▍    | 6/11 [00:13<00:11,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7194247245788574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7220149040222168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7208381295204163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.72283935546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  91%|█████████ | 10/11 [00:20<00:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7423010468482971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7186816930770874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:   9%|▉         | 1/11 [00:01<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7267043590545654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  18%|█▊        | 2/11 [00:03<00:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7212738394737244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  27%|██▋       | 3/11 [00:05<00:15,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7296324372291565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  36%|███▋      | 4/11 [00:09<00:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7213701605796814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  45%|████▌     | 5/11 [00:11<00:14,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7157129049301147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7158142924308777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7244541049003601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7200593948364258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  82%|████████▏ | 9/11 [00:18<00:03,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7150096893310547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  91%|█████████ | 10/11 [00:20<00:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7274829745292664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7328810095787048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:   9%|▉         | 1/11 [00:01<00:19,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7266672253608704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  18%|█▊        | 2/11 [00:03<00:17,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7179184556007385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  27%|██▋       | 3/11 [00:08<00:23,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7231310606002808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  36%|███▋      | 4/11 [00:09<00:17,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7144427299499512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  45%|████▌     | 5/11 [00:11<00:13,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7198529839515686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7142902612686157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7144299745559692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7257034182548523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  82%|████████▏ | 9/11 [00:19<00:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7109796404838562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  91%|█████████ | 10/11 [00:21<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7126175761222839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.712571382522583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:   9%|▉         | 1/11 [00:01<00:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.713473379611969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  18%|█▊        | 2/11 [00:05<00:27,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7211145758628845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  27%|██▋       | 3/11 [00:07<00:20,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7124940156936646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  36%|███▋      | 4/11 [00:09<00:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7212578058242798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  45%|████▌     | 5/11 [00:11<00:12,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7241895794868469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7288814783096313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7109537720680237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  73%|███████▎  | 8/11 [00:17<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7107380032539368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  82%|████████▏ | 9/11 [00:19<00:03,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7103511095046997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  91%|█████████ | 10/11 [00:20<00:01,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7137489914894104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7150452733039856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/300:   0%|          | 0/11 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2964214/603521227.py\", line 20, in <module>\n",
      "    loss = diffusion.forward(y0=y, y_cond=X)\n",
      "  File \"/tmp/ipykernel_2964214/913358632.py\", line 133, in forward\n",
      "    noise_hat = self.eps_model(torch.cat([y_noisy, y_cond], dim=1) if y_cond is not None else y_noisy, sample_gammas)\n",
      "  File \"/home/mingdayang/miniconda3/envs/unibev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1123, in _call_impl\n",
      "    hook_result = hook(self, input, result)\n",
      "  File \"/home/mingdayang/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\", line 114, in <lambda>\n",
      "    mod, inp, outp, log_track_params\n",
      "  File \"/home/mingdayang/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\", line 108, in parameter_log_hook\n",
      "    self.log_tensor_stats(data.cpu(), \"parameters/\" + prefix + name)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2964214/603521227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2964214/913358632.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y0, y_cond)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mnoise_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_cond\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_gammas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(mod, inp, outp)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 lambda mod, inp, outp: parameter_log_hook(\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 )\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36mparameter_log_hook\u001b[0;34m(module, input_, output, log_track)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2964214/603521227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m   3672\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3673\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexception_raised\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_finish\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"finishing run {self._get_path()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mtel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0;31m# Pop this run (hopefully) from the run stack, to support the \"reinit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/telemetry.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exctype, excinst, exctb)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_telemetry_callback\u001b[0;34m(self, telem_obj)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelem_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_telemetry_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_telemetry_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_flushed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_telemetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_flushed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_telemetry\u001b[0;34m(self, telem)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_telemetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTelemetryRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelemetry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtelem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_job_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJobInputRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMailboxHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x72415c0d95d0>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#  noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# simple training loop using the existing `tensor` as toy data\n",
    "device = 'cuda'\n",
    "diffusion.to(device)\n",
    "diffusion.eps_model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(diffusion.eps_model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 300\n",
    "val_interval = 10\n",
    "\n",
    "with wandb.init(project=\"diffusion_test\", config=hyperparameters):\n",
    "    wandb.watch(diffusion.eps_model, log=\"all\", log_freq=10)\n",
    "    for epoch in range(epochs):\n",
    "        diffusion.set_new_noise_schedule(phase='train')\n",
    "        train_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            X, y = batch['img_bev_embed'], batch['pts_bev_embed']\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = diffusion.forward(y0=y, y_cond=X)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"Batch Loss: {loss.item()}\")\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        wandb.log({'train_loss': avg_train_loss}, step=epoch)\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ae35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3590a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdc628",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoints/diffusion_model_square.pth')\n",
    "\n",
    "Unet=UNet(**checkpoint['model_config'])\n",
    "Unet.load_state_dict(checkpoint['model_state_dict'])\n",
    "diffusion = DenoiseDiffusion(Unet, checkpoint['beta_schedule'], 'cuda:0')\n",
    "\n",
    "diffusion.set_new_noise_schedule(phase='test')\n",
    "print(diffusion.eps_model.in_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diffusion.set_new_noise_schedule(phase='test')\n",
    "y_ddpm, _ = diffusion.ddpm_sampler(1)\n",
    "y_ddim, _ = diffusion.ddim_sampler(1, steps=10, eta=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09905bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "y, _ = diffusion.ddim_sampler(1, steps=30, clip_denoised=True)\n",
    "end = time.time()\n",
    "print(y)\n",
    "print(f\"Max: {torch.amax(y)}, Min: {torch.amin(y)}\")\n",
    "print(f\"Execution time: {end - start}\")\n",
    "plt.imshow(y.cpu().numpy()[0, 0], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db89271",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "y, _ = diffusion.ddim_sampler(1, steps=50, clip_denoised=True)\n",
    "end = time.time()\n",
    "print(y)\n",
    "print(f\"Max: {torch.amax(y)}, Min: {torch.amin(y)}\")\n",
    "print(f\"Execution time: {end - start}\")\n",
    "plt.imshow(y.cpu().numpy()[0, 0], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ddpm, _ = diffusion.ddpm_sampler(1)\n",
    "y_ddim, _ = diffusion.ddim_sampler(1, steps=10)\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "im0 = ax[0].imshow(y_ddpm.cpu().numpy()[0, 0], cmap='viridis')\n",
    "im1 = ax[1].imshow(y_ddim.cpu().numpy()[0, 0], cmap='viridis')\n",
    "\n",
    "fig.colorbar(im0, ax=ax[0])\n",
    "fig.colorbar(im1, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_config, beta_schedule):\n",
    "    save_temp = {}\n",
    "    save_temp['model_state_dict'] = model.eps_model.state_dict()\n",
    "    save_temp['model_config'] = model_config\n",
    "    save_temp['beta_schedule'] = beta_schedule\n",
    "    torch.save(save_temp, 'checkpoints/temp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8190c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unibev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
