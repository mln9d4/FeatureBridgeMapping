{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d12b707",
   "metadata": {},
   "source": [
    "# DDPM forward and reverse process implementation\n",
    "Paper: https://arxiv.org/abs/2006.11239\n",
    "\n",
    "## Forward Process\n",
    "Fowrad process adss noise to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2908a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from data.dataset import BEVFeaturesDataset, PaddDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import wandb\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d21e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c3b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from inspect import isfunction\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128,\n",
    "        eps=1e-5\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn, eps=eps))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True, eps=eps),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False, eps=eps)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn, eps=eps))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups, eps=eps)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "\n",
    "# PositionalEncoding Source： https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype, device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat([torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim, eps=eps),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups, eps=eps)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout, eps=eps)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel, eps=eps)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\"bnchw, bncyx -> bnhwyx\", query, key).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout, eps=eps)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups, eps=eps)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d22a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, var\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-6, linear_end=1e-2, cosine_s=8e-3):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that is a function of the number of diffusion steps.\n",
    "    Return:\n",
    "        betas: a numpy array of shape (n_timestep,) that defines the beta schedule\n",
    "    \"\"\"\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return torch.from_numpy(betas) if betas.type == np.ndarray else betas\n",
    "\n",
    "\n",
    "class DenoiseDiffusion(nn.Module):\n",
    "    def __init__(self, eps_model, beta_schedule, loss_fn=nn.L1Loss()):\n",
    "        super().__init__()\n",
    "        # Parameters for training\n",
    "        self.loss_fn = loss_fn\n",
    "        self.eps_model = eps_model\n",
    "        self.beta_schedule = beta_schedule\n",
    "\n",
    "\n",
    "        # Parameters for diffusion process         \n",
    "    def set_new_noise_schedule(self, device=torch.device('cuda'), phase='train'):\n",
    "        self.n_steps = self.beta_schedule[phase]['n_timestep']\n",
    "        to_torch = partial(torch.as_tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(**self.beta_schedule[phase])\n",
    "        # self.betas = beta.type(dtype=torch.float32).to(self.eps_model.device)\n",
    "        alphas = 1. - betas\n",
    "        gammas = torch.cumprod(alphas, dim=0)\n",
    "        sigmas = torch.sqrt(1.0 - torch.pow(alphas, 2))\n",
    "        lambdas = torch.log(alphas / sigmas)\n",
    "\n",
    "        self.register_buffer(\"betas\", to_torch(betas))\n",
    "        self.register_buffer(\"alphas\", to_torch(alphas))\n",
    "        self.register_buffer(\"gammas\", to_torch(gammas))\n",
    "        self.register_buffer(\"sigmas\", to_torch(sigmas))\n",
    "        self.register_buffer(\"lambdas\", to_torch(lambdas))\n",
    "\n",
    "\n",
    "    # def to(self, device):\n",
    "        # self.eps_model = self.eps_model.to(device)\n",
    "\n",
    "    def gather(self, tensor, t):\n",
    "        \"\"\"\n",
    "        Gather the values of x at the time steps t.\n",
    "        Makes it compatible with the shape of x0, which is (B, C, H, W).\n",
    "        Args:\n",
    "            tensor: a tensor of shape (n_steps,)\n",
    "            t: a tensor of shape (B,)\n",
    "        Return:\n",
    "            a tensor of shape (B, 1, 1, 1) that contains the values of x at the time steps t\n",
    "        \"\"\"\n",
    "        t = tensor.gather(-1, t)\n",
    "        return t.reshape(-1, 1, 1, 1)\n",
    "    \n",
    "        # We need a function that samples the batch \n",
    "    def q_sample(self, y0, sample_gammas, noise=None):\n",
    "        \"\"\"\n",
    "        Sample from q(yt|y0), reading same as sample xt at step t given x0.\n",
    "        Other implementations also use function q_xt_x0 first but we can directly implement it here.\n",
    "        Args:\n",
    "            y0: the original data, shape (B, C, H, W)\n",
    "            sample_gammas: the gamma values for sampling, shape (B,)\n",
    "            noise: the noise, shape (B, C, H, W)\n",
    "        Return:\n",
    "            yt: the noisy data at time step t, shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        eps = torch.randn_like(y0, device=y0.device) if noise is None else noise\n",
    "        \n",
    "        return (\n",
    "            torch.sqrt(sample_gammas) * y0 + torch.sqrt(1 - sample_gammas) * eps\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, y0, y_cond=None):\n",
    "        \"\"\"\n",
    "        Algorithm 1 in Denoising Diffusion Probalisitic Models\n",
    "\n",
    "        Args:\n",
    "            y0: the original data, shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        b, *_ = y0.shape\n",
    "\n",
    "        t = torch.randint(1, self.n_steps, (b,), device=y0.device, dtype=torch.long)\n",
    "        # Select a random gamma for each sample in the batch, which is between gamma_t and gamma_t-1 of generated timesteps t. This is to make the training more stable and avoid overfitting to specific timesteps.\n",
    "        gamma_t1 = self.gather(self.gammas, t - 1)\n",
    "        gamma_t2 = self.gather(self.gammas, t)\n",
    "        sample_gammas = (gamma_t2 - gamma_t1) * torch.rand((b, 1, 1, 1), device=y0.device) + gamma_t1\n",
    "        sample_gammas = sample_gammas\n",
    "\n",
    "        # Create the noise to compare it to the predicted noise, which is used for training the model. This is the noise added to the original data to get the noisy data at time step t.\n",
    "        noise = torch.randn_like(y0, device=y0.device)\n",
    "        y_noisy = self.q_sample(y0, sample_gammas, noise=noise)\n",
    "\n",
    "        noise_hat = self.eps_model(torch.cat([y_noisy, y_cond], dim=1) if y_cond is not None else y_noisy, sample_gammas)\n",
    "\n",
    "        loss = self.loss_fn(noise_hat, noise)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    # Samplers\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddpm_sampler(self, n_samples, y_cond=None, sample_inter=10, clip_denoised=True):\n",
    "        \"\"\"\n",
    "        https://arxiv.org/pdf/2006.11239\n",
    "        Implementation of algorithm 2. However, to keep sampling stable we calculate the start from noise, clamp it and use the posterior of equation 7 to calculate y_t-1.\n",
    "        We use equation 15 to calculate y_0 (start from noise), then clamp it. Then we use equation 7 to calculate y_t-1 = mean + sigma * z\n",
    "        \"\"\"\n",
    "        y = torch.randn(n_samples, self.eps_model.out_channel, self.eps_model.image_size, self.eps_model.image_size, device=y_cond.device)\n",
    "        ret_arr = y.clone()\n",
    "        for i in tqdm(reversed(range(self.n_steps)), desc='DDPM sampler', total=self.n_steps):\n",
    "            z = torch.randn_like(y) if i > 1 else torch.zeros_like(y)   \n",
    "            t_tensor = torch.full((n_samples,), i, device=y_cond.device, dtype=torch.long)\n",
    "\n",
    "            gamma_t = self.gather(self.gammas, t_tensor)\n",
    "            gamma_t_prev = self.gather(self.gammas, t_tensor - 1) if i > 0 else torch.ones_like(gamma_t)\n",
    "            beta_t = self.gather(self.betas, t_tensor)\n",
    "            alpha_t = self.gather(self.alphas, t_tensor)\n",
    "\n",
    "            y_0_tilde = (y - torch.sqrt(1-gamma_t)*self.eps_model(torch.cat([y, y_cond], dim=1) if y_cond is not None else y, gamma_t)) / torch.sqrt(gamma_t) # predict start\n",
    "\n",
    "            if clip_denoised:\n",
    "                y_0_tilde = torch.clamp(y_0_tilde, -1., 1.)\n",
    "\n",
    "            # eta = (y - torch.sqrt(alpha_t)*y_0_tilde) / torch.sqrt(1-alpha_t)\n",
    "\n",
    "            # Calculate posterior mean and variance\n",
    "            mean = (torch.sqrt(gamma_t_prev) * beta_t * y_0_tilde) / (1 - gamma_t) + (torch.sqrt(alpha_t) * (1 - gamma_t_prev) * y) / (1 - gamma_t)\n",
    "\n",
    "            sigma = (1 - gamma_t_prev) * beta_t / (1 - gamma_t)\n",
    "\n",
    "            y = mean + sigma * z\n",
    "\n",
    "            if i & sample_inter ==0:\n",
    "                ret_arr = torch.cat((ret_arr, y), dim=0)\n",
    "\n",
    "        return y, ret_arr\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_sampler(self, y_cond=None, noise=None, sample_inter=10, steps=50, clip_denoised=True, eta=0.0):\n",
    "        \"\"\"\n",
    "        DDIM sampler from https://arxiv.org/abs/2010.02502\n",
    "        With eta=0, it becomes a deterministic sampler, which is the one we will use in this implementation. With eta>0, it becomes a stochastic sampler, which is similar to the DDPM sampler but with different noise scale. \n",
    "        \"\"\"\n",
    "        y = torch.randn_like(y_cond, device=y_cond.device) if noise is None else noise\n",
    "        ret_arr = y.clone()\n",
    "        step_size = self.n_steps // steps\n",
    "\n",
    "        for i in tqdm(range(steps), desc='DDIM sampling loop timestep', total=steps):\n",
    "            t = self.n_steps - i * step_size\n",
    "            t_tensor = torch.full((y_cond.shape[0],), t, dtype=torch.long, device=y_cond.device)\n",
    "\n",
    "            gamma = self.gather(self.gammas, t_tensor - 1)\n",
    "            \n",
    "            # Make sure that when t_tensor - step_size - 1 is negative, we use gamma_prev = 1, which means that we are at the final step and we should not add any noise.\n",
    "            gamma_prev = self.gather(self.gammas, torch.clamp(t_tensor - step_size - 1, min=0)) if (t_tensor - step_size - 1 >= 0).any() else torch.ones_like(gamma)\n",
    "            noise_pred = self.eps_model(torch.cat([y, y_cond], dim=1) if y_cond is not None else y, gamma)\n",
    "\n",
    "            y0_pred = (y - torch.sqrt(1 - gamma) * noise_pred) / torch.sqrt(gamma)\n",
    "            \n",
    "            # Clamp prediction to stablize sampling\n",
    "            if clip_denoised:\n",
    "                y0_pred = torch.clamp(y0_pred, -1., 1.)\n",
    "\n",
    "            sigma_t = eta * torch.sqrt((1 - gamma_prev) / (1 - gamma)) * torch.sqrt(1-gamma / gamma_prev)\n",
    "\n",
    "            dir_yt = torch.sqrt(1 - gamma_prev - torch.pow(sigma_t, 2)) * noise_pred\n",
    "            \n",
    "            \n",
    "            y = torch.sqrt(gamma_prev) * y0_pred + dir_yt + sigma_t * torch.randn_like(y)\n",
    "\n",
    "        return y, ret_arr\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def dpm_solver_multi_step_sampler(self, n_samples, y_cond=None, sample_inter=10, steps=10, clip_denoised=True):\n",
    "        \"\"\"\n",
    "        Implement multistep from https://arxiv.org/pdf/2211.01095\n",
    "        \"\"\"\n",
    "        step_size = self.n_steps // steps\n",
    "\n",
    "\n",
    "        yT = torch.randn(n_samples, self.eps_model.out_channel, self.eps_model.image_size, self.eps_model.image_size, device=y_cond.device)\n",
    "        ret_arr = yT.clone()\n",
    "\n",
    "        ytilde = yT\n",
    "\n",
    "\n",
    "        t_0 = torch.full((n_samples,), self.n_steps - 1, device=y_cond.device, dtype=torch.long)\n",
    "        t_1 = torch.full((n_samples,), self.n_steps - step_size - 1, device=y_cond.device, dtype=torch.long)\n",
    "        t_2 = torch.full((n_samples,), self.n_steps - 2 * step_size - 1, device=y_cond.device, dtype=torch.long)\n",
    "        # print(self.lambdas.shape)\n",
    "        # print(t_1)\n",
    "        # print(t_0)\n",
    "        h_i_prev = self.gather(self.lambdas, t_1) - self.gather(self.lambdas, t_0)\n",
    "\n",
    "        # Buffer P and Q for multi_step sampling. P = -2 and Q = -1 in timestepe space, which means that they are the data prediction at t_i-2 and t_i-1 respectively. We will update them in each step and use them to calculate the data prediction at t_i.\n",
    "        P = self.data_prediction(ytilde, y_cond=y_cond, t=t_0) # y_theta_0\n",
    "        if clip_denoised:\n",
    "            P = torch.clamp(P, -1., 1.)\n",
    "        y_tilde = (self.gather(self.sigmas, t_1)/self.gather(self.sigmas, t_0)) * ytilde - self.gather(self.alphas, t_1) * (torch.exp(-h_i_prev) - 1) * P\n",
    "        Q = self.data_prediction(y_tilde, y_cond=y_cond, t=t_1) # y_theta_2\n",
    "        if clip_denoised:\n",
    "            Q = torch.clamp(Q, -1, 1.)\n",
    "        \n",
    "\n",
    "        for i in tqdm((range(2, steps)), desc='DPM-Solver++(2M) sampler', initial=2, total=steps):\n",
    "            t_cur = self.n_steps - i * step_size - 1\n",
    "            t_prev = self.n_steps - (i - 1) * step_size - 1\n",
    "\n",
    "            t_prev_tensor = torch.full((n_samples,), t_prev, device=y_cond.device, dtype=torch.long)\n",
    "            t_cur_tensor = torch.full((n_samples,), t_cur, device=y_cond.device, dtype=torch.long)\n",
    "\n",
    "            h_i_cur = self.gather(self.lambdas, t_cur_tensor) - self.gather(self.lambdas, t_prev_tensor)\n",
    "            r_i = h_i_prev / h_i_cur\n",
    "\n",
    "            D_i = (1 + 1 / (2 * r_i)) * Q - 1 / (2 * r_i) * P\n",
    "\n",
    "            y_tilde = (self.gather(self.sigmas, t_cur_tensor) / self.gather(self.sigmas, t_prev_tensor)) * y_tilde - self.gather(self.alphas, t_cur_tensor) * (torch.exp(-h_i_cur) - 1) * D_i\n",
    "            \n",
    "            h_i_prev = h_i_cur\n",
    "            P = Q.clone()\n",
    "            if i < self.n_steps:\n",
    "                Q = self.data_prediction(y_tilde, y_cond=y_cond, t=t_cur_tensor)\n",
    "                if clip_denoised:\n",
    "                    Q = torch.clamp(Q, -1., 1.)\n",
    "\n",
    "            if i & sample_inter == 0:\n",
    "                ret_arr = torch.cat((ret_arr, y_tilde), dim=0)\n",
    "\n",
    "        return y_tilde, ret_arr\n",
    "    \n",
    "    def data_prediction(self, yt, y_cond=None, t=None):\n",
    "        gamma = self.gather(self.gammas, t).to(yt.device)\n",
    "        noise_pred = self.eps_model(torch.cat([yt, y_cond], dim=1) if y_cond is not None else yt, gamma)\n",
    "        y0_hat = (yt - torch.sqrt(1 - gamma) * noise_pred) / torch.sqrt(gamma)\n",
    "\n",
    "        return y0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad3ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_schedule = dict(\n",
    "    train=dict(\n",
    "        schedule='cosine',\n",
    "        n_timestep=2000,\n",
    "        cosine_s=8e-3,\n",
    "    ),\n",
    "    test=dict(\n",
    "        schedule='linear',\n",
    "        n_timestep=1000,\n",
    "        linear_start=1e-5,\n",
    "        linear_end=1e-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_config = dict(\n",
    "    in_channel=512,\n",
    "    out_channel=256,\n",
    "    inner_channel=128,\n",
    "    norm_groups=32,\n",
    "    channel_mults=(1, 2, 4, 8),\n",
    "    attn_res=(25,),\n",
    "    res_blocks=2,\n",
    "    dropout=0,\n",
    "    with_noise_level_emb=True,\n",
    "    image_size=200,\n",
    "    eps=1e-5\n",
    ")\n",
    "\n",
    "hyperparameters = dict(\n",
    "    model_config=model_config,\n",
    "    beta_schedule=beta_schedule,\n",
    "    batch_size=6,\n",
    ")\n",
    "\n",
    "Unet = UNet(**model_config)\n",
    "diffusion = DenoiseDiffusion(Unet, beta_schedule)\n",
    "diffusion.set_new_noise_schedule(phase='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102b4be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM sampling loop timestep:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM sampling loop timestep: 100%|██████████| 50/50 [00:21<00:00,  2.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.9052,  0.6056,  0.7539,  ...,  0.7089,  0.9348, -0.7608],\n",
       "           [-0.4291,  0.1744,  0.9985,  ..., -0.5786,  0.6089,  0.0615],\n",
       "           [-0.9999,  0.4726, -0.9195,  ..., -0.4503, -0.9907,  0.6652],\n",
       "           ...,\n",
       "           [ 0.2648, -0.5884, -0.0404,  ...,  0.4837, -0.5868,  0.0095],\n",
       "           [ 1.0000,  0.6826, -0.7567,  ..., -0.8508, -0.3490,  0.8485],\n",
       "           [-0.7334, -0.8856,  1.0000,  ..., -0.6242,  0.2219,  1.0000]],\n",
       " \n",
       "          [[ 0.9595, -0.9917, -0.8975,  ...,  0.4510, -0.6107, -0.7388],\n",
       "           [-0.5226,  0.1377,  0.1038,  ...,  0.6675, -0.5343, -0.9889],\n",
       "           [-0.5597,  1.0000, -0.1788,  ..., -0.2632,  0.4166, -1.0000],\n",
       "           ...,\n",
       "           [ 0.9991,  0.0395, -0.5515,  ...,  0.8632,  0.7626,  0.5206],\n",
       "           [ 0.8184, -0.4611, -0.9966,  ...,  0.9069,  0.4638,  0.6909],\n",
       "           [-0.8151,  0.6977,  0.9526,  ...,  0.5655, -0.9994,  0.9947]],\n",
       " \n",
       "          [[ 0.9260, -0.3743, -0.3316,  ..., -0.9889,  0.9998,  0.6551],\n",
       "           [ 0.9865, -1.0000,  0.9735,  ..., -0.9448,  0.5142,  0.6767],\n",
       "           [-0.8346, -0.1448, -0.5216,  ...,  0.7001, -0.5324,  0.6314],\n",
       "           ...,\n",
       "           [-0.7627, -1.0000,  0.9861,  ..., -0.8851, -0.7258,  0.8087],\n",
       "           [ 0.3444, -0.4896,  0.3392,  ..., -0.9469, -1.0000, -0.5263],\n",
       "           [-0.8388, -0.8133,  0.8234,  ...,  0.3670, -0.9811, -0.9671]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.4417,  0.5991, -0.6972,  ...,  0.9836,  1.0000, -0.9726],\n",
       "           [-0.6629,  0.6465,  0.7213,  ...,  0.6257, -0.1933,  0.4754],\n",
       "           [ 0.2490, -0.0642, -0.4571,  ..., -0.4793,  0.8274,  0.8788],\n",
       "           ...,\n",
       "           [ 0.9390, -0.1291, -0.1637,  ...,  0.8307,  0.6370,  0.6621],\n",
       "           [-0.7345, -0.0311,  0.4099,  ...,  0.9678,  0.1651, -0.4524],\n",
       "           [-0.5784,  0.8644,  0.7914,  ..., -1.0000,  0.8941, -1.0000]],\n",
       " \n",
       "          [[ 0.9643, -0.8000, -0.3779,  ..., -0.1776,  0.7790, -0.6233],\n",
       "           [ 0.0277, -0.7095, -0.6013,  ...,  0.7775, -1.0000,  0.9799],\n",
       "           [-0.9975, -0.0435,  0.5858,  ..., -0.9684, -0.7606,  0.3853],\n",
       "           ...,\n",
       "           [-1.0000,  0.7958,  0.4364,  ..., -0.0880,  0.9915, -0.9787],\n",
       "           [ 0.8948,  0.5206, -0.2592,  ..., -0.5500, -0.2001,  0.6105],\n",
       "           [-0.9034, -0.9020,  0.5122,  ..., -1.0000,  0.9601, -0.9887]],\n",
       " \n",
       "          [[ 0.1280,  0.5875,  0.8647,  ..., -0.6159, -0.6581,  0.8129],\n",
       "           [ 0.9844,  0.3912, -1.0000,  ...,  0.4431, -0.6126,  0.8537],\n",
       "           [ 0.6507, -0.4541,  0.5129,  ...,  0.3630, -0.7269,  0.9498],\n",
       "           ...,\n",
       "           [ 0.4920,  0.7252,  0.3205,  ..., -0.2087,  0.4785, -0.7712],\n",
       "           [ 0.6443,  0.7574, -0.9805,  ..., -0.2734, -1.0000,  0.7563],\n",
       "           [ 0.4900,  1.0000,  0.6204,  ..., -0.0232,  0.7296, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-0.9936, -0.8704,  0.0858,  ..., -0.9048, -0.5492, -0.4415],\n",
       "           [-0.9252, -0.2206, -0.9105,  ..., -1.0000, -0.7601,  0.9760],\n",
       "           [ 0.9542, -0.0441,  0.5011,  ..., -0.9996,  0.9997,  0.9568],\n",
       "           ...,\n",
       "           [-0.5560, -0.7245, -0.1286,  ..., -0.5914,  0.3192, -0.1697],\n",
       "           [ 0.6688, -0.5619,  0.0749,  ...,  0.0086,  0.4616,  1.0000],\n",
       "           [-0.9345, -0.9786,  0.3854,  ..., -0.8032,  0.5568, -0.8432]],\n",
       " \n",
       "          [[-1.0000, -0.5183,  0.8485,  ..., -0.9753, -0.8761, -0.4204],\n",
       "           [-0.6159,  0.3071, -0.2245,  ..., -0.4401, -0.2689, -0.6173],\n",
       "           [ 0.5353, -0.5987, -0.8455,  ..., -0.4083, -0.0456,  0.9994],\n",
       "           ...,\n",
       "           [-0.1051, -0.9233, -0.4083,  ...,  0.6041,  0.0584,  0.3838],\n",
       "           [-0.7485,  0.7179, -0.8133,  ...,  0.7550,  0.3621, -1.0000],\n",
       "           [ 0.8691, -0.7100,  0.7954,  ...,  0.4771,  0.8849,  0.9942]],\n",
       " \n",
       "          [[-0.4265, -0.9140,  0.8352,  ...,  0.9774,  1.0000,  0.9726],\n",
       "           [-0.6565, -0.9569,  0.6350,  ...,  1.0000, -0.9967,  1.0000],\n",
       "           [-1.0000,  0.2559,  0.3341,  ..., -0.8027, -0.8881, -0.5554],\n",
       "           ...,\n",
       "           [-0.9629,  0.6901, -0.8919,  ...,  1.0000,  0.9997, -0.1912],\n",
       "           [-0.8873,  0.6029,  0.1269,  ..., -0.8264, -0.2530, -0.7307],\n",
       "           [ 0.4732,  0.5562, -0.8741,  ..., -0.9016, -0.8988,  0.3223]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.8975,  1.0000,  0.4906,  ...,  0.2176,  0.9876, -0.8117],\n",
       "           [-0.6085, -0.5036,  0.5718,  ...,  0.3114, -0.9960,  0.7351],\n",
       "           [ 0.6977,  0.1889, -0.4657,  ...,  0.6272, -0.1524,  0.6198],\n",
       "           ...,\n",
       "           [-0.6246,  0.9794,  0.8302,  ...,  0.8703,  0.1384, -0.9676],\n",
       "           [-0.4613, -0.8394,  0.9218,  ..., -0.4171,  0.5969, -0.5174],\n",
       "           [ 0.1764, -0.9954,  0.7156,  ...,  0.7057,  0.9989,  0.5791]],\n",
       " \n",
       "          [[-0.9881, -0.9483, -0.5200,  ...,  1.0000,  1.0000,  0.3921],\n",
       "           [ 0.1937, -0.7718, -0.4055,  ...,  0.8910, -0.4345, -0.5432],\n",
       "           [-0.8030, -0.4757,  0.0789,  ...,  0.3471, -0.8220,  0.9248],\n",
       "           ...,\n",
       "           [-0.6837, -0.6245, -0.3921,  ..., -0.2342, -0.7208, -0.3044],\n",
       "           [ 0.8546, -0.8845, -0.4538,  ...,  0.6869,  0.4627, -0.6143],\n",
       "           [ 0.9458, -0.7151,  0.8157,  ...,  0.9993,  1.0000, -0.7200]],\n",
       " \n",
       "          [[ 0.7752, -0.7779, -0.2148,  ...,  0.7843,  0.7965,  0.8590],\n",
       "           [ 0.9999,  0.7437,  0.6140,  ...,  0.8572,  0.4807, -0.6520],\n",
       "           [-0.1421,  0.8328,  0.3479,  ...,  0.7541, -0.8827, -0.8938],\n",
       "           ...,\n",
       "           [-0.4282, -0.4703,  0.4177,  ...,  0.3558, -0.7697,  0.2984],\n",
       "           [ 1.0000,  0.5372,  0.9999,  ...,  0.5941, -0.2383, -0.9481],\n",
       "           [-0.9994,  0.7147, -0.5963,  ..., -0.5099, -0.7859,  0.6579]]],\n",
       " \n",
       " \n",
       "         [[[-0.7799,  0.6604, -1.0000,  ...,  0.1033,  0.8222,  0.6901],\n",
       "           [-0.0527, -0.6422,  0.9568,  ...,  0.4319, -0.6336,  0.1566],\n",
       "           [-0.2463,  0.0096,  0.0607,  ...,  0.5506, -1.0000,  0.4187],\n",
       "           ...,\n",
       "           [ 0.9521, -0.7804,  0.5540,  ...,  1.0000,  0.6328,  0.9999],\n",
       "           [ 0.6200,  0.2661,  0.9775,  ...,  0.7328, -0.1214, -0.6273],\n",
       "           [ 0.8533, -0.9722, -0.3814,  ..., -0.5828, -0.5646,  0.9892]],\n",
       " \n",
       "          [[ 0.6335, -0.9302, -0.9506,  ...,  1.0000,  1.0000,  0.9132],\n",
       "           [ 0.7148, -0.8268,  0.9768,  ...,  0.7033, -0.9219, -0.9990],\n",
       "           [ 0.3508, -0.9927, -0.9613,  ..., -0.7975, -0.4357,  0.6744],\n",
       "           ...,\n",
       "           [-0.8815,  0.7665,  0.4356,  ...,  0.0100,  0.0914,  0.8784],\n",
       "           [ 0.9993,  1.0000,  0.3842,  ..., -0.1176, -0.9580, -0.3412],\n",
       "           [ 0.4844,  0.4490,  0.4447,  ..., -0.7627,  0.9476, -0.9539]],\n",
       " \n",
       "          [[-0.7250, -0.8850,  0.9687,  ..., -0.4615, -0.3414, -0.6533],\n",
       "           [-0.8529,  0.6865, -0.9978,  ..., -0.2291,  0.3929, -0.8196],\n",
       "           [ 1.0000, -0.5118, -0.5092,  ..., -0.3118,  0.3192, -0.9982],\n",
       "           ...,\n",
       "           [-0.6995, -0.8224,  0.9995,  ..., -0.0848, -0.9698, -0.8803],\n",
       "           [-0.1404, -0.7386,  0.8910,  ..., -0.8218, -0.8127,  0.6878],\n",
       "           [-0.8385, -1.0000,  0.8946,  ..., -0.6556,  0.6617, -0.5447]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.9852, -0.4164,  0.4696,  ..., -0.7898, -0.8142,  0.9317],\n",
       "           [ 0.2719,  0.9757,  0.0585,  ...,  0.4141, -0.5597,  0.3259],\n",
       "           [ 0.0453,  0.8374, -0.9226,  ..., -0.8727,  1.0000,  0.9266],\n",
       "           ...,\n",
       "           [ 0.7825,  0.4059, -0.3124,  ...,  0.1088, -0.1472, -0.8768],\n",
       "           [ 0.0470,  0.6105, -0.9936,  ...,  0.9999,  0.4921, -0.5145],\n",
       "           [ 0.8731,  0.3846, -0.7990,  ..., -0.3365, -0.2852,  0.4709]],\n",
       " \n",
       "          [[ 0.8712, -0.8209, -0.6360,  ..., -0.8327,  0.9997,  1.0000],\n",
       "           [-0.6780, -0.7949, -0.9975,  ...,  0.9782, -0.6828,  0.0560],\n",
       "           [-0.6906,  0.0613,  0.2953,  ..., -0.9445, -0.6486,  0.5778],\n",
       "           ...,\n",
       "           [-0.7998, -1.0000, -0.6791,  ...,  0.6434,  1.0000,  0.4040],\n",
       "           [-0.5326,  0.3916, -0.6966,  ..., -0.7085,  0.4394, -0.2476],\n",
       "           [ 0.5428,  1.0000,  0.2753,  ...,  1.0000, -0.5544,  0.7244]],\n",
       " \n",
       "          [[ 0.7523,  0.7783,  0.7913,  ...,  0.8419, -1.0000, -0.6938],\n",
       "           [ 0.5694,  0.4713,  0.5892,  ..., -0.9162,  0.2602,  0.7613],\n",
       "           [-0.1225, -1.0000, -1.0000,  ...,  0.9677, -0.5961, -0.3735],\n",
       "           ...,\n",
       "           [-0.7182,  1.0000,  0.4571,  ..., -0.7543,  0.8649, -1.0000],\n",
       "           [ 0.6973,  0.0786,  1.0000,  ...,  1.0000,  0.7073, -0.5754],\n",
       "           [-0.8465,  0.3524,  0.1158,  ...,  0.0580,  0.4721,  0.6609]]],\n",
       " \n",
       " \n",
       "         [[[ 0.9762,  0.1844,  0.3637,  ..., -0.7455,  0.9611,  0.9752],\n",
       "           [ 0.8117,  0.7296,  1.0000,  ..., -0.2617,  0.8048, -0.9784],\n",
       "           [ 0.7904, -0.5779,  0.1371,  ..., -0.8231,  0.0874, -0.9688],\n",
       "           ...,\n",
       "           [ 0.7444, -0.4613,  0.1514,  ...,  0.4508,  0.8585,  0.9918],\n",
       "           [ 0.5989, -0.9525, -0.6774,  ..., -0.6731, -0.5673,  0.9670],\n",
       "           [ 0.8675, -0.5578,  1.0000,  ..., -0.5094,  0.4869,  0.7545]],\n",
       " \n",
       "          [[-0.2558, -0.0641,  0.9029,  ..., -0.9991, -0.6003,  1.0000],\n",
       "           [ 0.9629, -0.8403,  0.7881,  ..., -0.6807, -0.9371, -0.7314],\n",
       "           [-0.6444,  0.8663,  0.3007,  ..., -0.9742, -0.9749, -0.1663],\n",
       "           ...,\n",
       "           [-0.6671,  0.1654,  1.0000,  ...,  0.7334,  0.9988,  0.3705],\n",
       "           [ 0.5758, -0.8544, -0.2019,  ...,  0.8429, -0.1802, -0.5372],\n",
       "           [-0.7872,  0.4077,  0.1431,  ..., -0.6442,  0.9999,  0.8812]],\n",
       " \n",
       "          [[ 0.9107, -0.2093, -0.2581,  ...,  0.7215, -0.2258,  0.4735],\n",
       "           [-0.8234, -0.0919, -0.4587,  ..., -0.9884,  0.4335,  0.6752],\n",
       "           [-0.1747, -0.0469, -0.1820,  ...,  1.0000, -0.1692, -0.6234],\n",
       "           ...,\n",
       "           [-0.3213,  0.4253, -0.0239,  ...,  0.3172, -0.4580, -0.8972],\n",
       "           [-0.5927,  0.6251, -0.2887,  ..., -0.3185, -0.9986,  0.2100],\n",
       "           [-0.7475, -0.7840, -0.6631,  ...,  1.0000, -0.2988,  0.6784]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.3806,  0.5676, -0.8174,  ..., -1.0000, -0.2100, -0.6393],\n",
       "           [-0.3239,  0.5945, -0.3223,  ...,  0.4830,  0.7481,  0.6360],\n",
       "           [ 0.6907, -0.9976, -0.2661,  ..., -0.8434, -0.6606,  0.7989],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000,  1.0000,  ..., -0.1633,  0.3023,  0.7932],\n",
       "           [-0.4801, -0.9863, -0.3028,  ...,  0.5953, -0.4872, -0.8470],\n",
       "           [-0.9944,  0.8769, -0.8055,  ..., -0.2238,  0.8198, -0.4774]],\n",
       " \n",
       "          [[-0.7802, -0.7290,  0.8641,  ..., -0.3059, -0.7594, -0.8938],\n",
       "           [-0.7310,  0.7076, -0.2184,  ..., -0.6883,  0.9998, -1.0000],\n",
       "           [-0.1981,  0.4103,  0.7093,  ...,  0.5897,  0.7875,  0.6649],\n",
       "           ...,\n",
       "           [ 1.0000,  0.0384, -1.0000,  ..., -0.5564,  0.9675, -0.7107],\n",
       "           [ 0.9963,  0.6720, -0.6296,  ..., -0.6241,  0.7035, -0.6249],\n",
       "           [-0.9923, -0.9902,  0.9194,  ...,  0.9992,  0.9064,  0.3275]],\n",
       " \n",
       "          [[ 0.2200,  0.9973,  0.6151,  ...,  0.6889, -0.5154, -0.7443],\n",
       "           [ 0.6808,  0.1038,  0.9360,  ...,  0.8211,  0.9927, -0.9778],\n",
       "           [ 0.8651, -0.6787, -1.0000,  ...,  0.4272, -0.4005, -0.8389],\n",
       "           ...,\n",
       "           [-1.0000, -0.9948, -1.0000,  ..., -0.2024, -0.1098,  1.0000],\n",
       "           [-0.8423, -1.0000, -0.8909,  ...,  0.7950,  0.7089,  0.6955],\n",
       "           [-0.2846, -0.4240,  0.4565,  ..., -0.9316,  0.5838,  0.7563]]],\n",
       " \n",
       " \n",
       "         [[[ 0.8682, -0.9935,  0.7545,  ...,  1.0000, -0.7397,  0.8543],\n",
       "           [-0.7407,  0.9919,  0.7574,  ...,  0.9112,  0.9588,  0.3512],\n",
       "           [-0.8622,  0.5111,  0.4768,  ...,  0.4306, -0.5512,  0.6001],\n",
       "           ...,\n",
       "           [ 1.0000, -0.8677,  0.4763,  ...,  0.5765,  0.1106, -0.6576],\n",
       "           [ 0.7035, -1.0000, -0.8879,  ...,  0.9966, -0.4764,  0.9943],\n",
       "           [ 0.2463, -0.0516, -0.8621,  ...,  0.7107,  0.6346, -0.6911]],\n",
       " \n",
       "          [[ 0.6987,  0.1986, -0.1121,  ..., -0.7080, -0.8622,  0.2291],\n",
       "           [-0.9903, -0.9884, -0.1071,  ..., -0.4557, -0.0701, -0.7896],\n",
       "           [ 0.1553,  0.3209, -0.8130,  ..., -0.6980,  0.4063, -1.0000],\n",
       "           ...,\n",
       "           [ 0.5912, -0.0385,  0.8298,  ...,  0.1677,  0.7590,  1.0000],\n",
       "           [-0.9183, -0.7743, -0.0044,  ..., -0.3245,  0.5455, -0.6410],\n",
       "           [-1.0000, -0.4603,  0.8833,  ...,  0.5876,  0.2897, -0.9964]],\n",
       " \n",
       "          [[ 0.9311, -1.0000,  0.7419,  ..., -0.9965, -0.5496, -0.7765],\n",
       "           [ 0.4965, -0.3752,  0.8584,  ..., -0.0377,  0.2870, -0.8164],\n",
       "           [ 0.5870, -0.6701,  0.0292,  ...,  0.8006, -0.9200, -0.0844],\n",
       "           ...,\n",
       "           [-0.7902,  0.3258, -0.4778,  ..., -0.4857,  0.8627, -0.4032],\n",
       "           [-0.5005, -1.0000, -0.2187,  ...,  0.1500,  0.0647, -0.6950],\n",
       "           [ 0.6829,  0.5077,  1.0000,  ..., -0.1290,  0.8479, -0.6454]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.9984, -0.8451, -0.4314,  ..., -0.8630,  0.6538,  0.4829],\n",
       "           [ 0.6590, -0.7811, -0.1452,  ..., -0.3657,  0.5790,  0.6950],\n",
       "           [-0.8968,  1.0000, -0.0670,  ..., -0.2344, -0.2485,  0.9119],\n",
       "           ...,\n",
       "           [ 0.8099,  1.0000,  0.1561,  ..., -0.9981, -0.6453, -0.9703],\n",
       "           [ 0.9612,  0.6648, -1.0000,  ..., -0.7262,  0.9058,  0.8543],\n",
       "           [ 0.8206, -0.4563, -0.1602,  ..., -0.8297,  0.7699,  0.5656]],\n",
       " \n",
       "          [[ 1.0000,  0.8563,  0.5395,  ..., -0.7979,  0.6838,  0.7030],\n",
       "           [ 0.4481, -0.9641, -0.9888,  ...,  0.0796, -0.9935, -0.9754],\n",
       "           [-0.9367, -0.8781,  0.8875,  ...,  0.6290,  0.1547,  0.2001],\n",
       "           ...,\n",
       "           [ 0.5339,  0.6429,  0.1823,  ..., -1.0000, -0.3245,  0.9968],\n",
       "           [ 0.7889,  0.9980,  0.5286,  ..., -0.0968, -0.3143,  0.6909],\n",
       "           [ 0.7199,  0.1208,  0.9826,  ...,  0.9023, -1.0000,  0.1328]],\n",
       " \n",
       "          [[ 0.2571,  0.9650, -1.0000,  ..., -0.7132,  0.6323, -1.0000],\n",
       "           [ 0.7859,  0.5853,  0.2169,  ..., -0.4927,  0.5053,  1.0000],\n",
       "           [-0.1331,  0.3991,  0.5652,  ...,  0.2602,  0.4011,  0.9996],\n",
       "           ...,\n",
       "           [-1.0000, -0.5062,  0.7851,  ...,  0.6086,  0.5233, -0.9878],\n",
       "           [-0.6228, -0.5416,  0.8351,  ...,  0.6079, -1.0000, -0.8113],\n",
       "           [-0.6649, -0.8179,  0.2831,  ...,  0.8295, -1.0000, -0.6887]]],\n",
       " \n",
       " \n",
       "         [[[-0.6132, -0.8187, -0.7099,  ..., -0.1834,  1.0000, -0.1141],\n",
       "           [-0.2113, -0.7260, -0.6668,  ..., -0.4158,  1.0000, -0.0076],\n",
       "           [-0.1653, -0.7938, -0.2336,  ...,  0.8735, -0.3868, -0.2979],\n",
       "           ...,\n",
       "           [-0.5946, -0.7303,  0.9170,  ..., -0.9675,  0.3390, -0.3565],\n",
       "           [-0.2613,  0.9999, -0.2523,  ..., -0.3064, -0.8112,  0.9807],\n",
       "           [-0.9130,  0.7124,  0.9613,  ..., -0.9137, -0.3258, -0.6743]],\n",
       " \n",
       "          [[ 0.7473, -0.2301,  0.4327,  ..., -0.8218, -0.5281, -0.9444],\n",
       "           [ 1.0000, -0.3868,  1.0000,  ..., -0.7585,  1.0000, -0.6755],\n",
       "           [-0.3645,  0.6183,  0.3247,  ..., -0.9369, -0.6125, -0.7036],\n",
       "           ...,\n",
       "           [ 0.9887, -0.6002,  0.3411,  ..., -0.9837, -0.3214,  0.9598],\n",
       "           [-0.9939,  0.9051,  0.6904,  ..., -0.7133,  0.5432, -0.9689],\n",
       "           [-0.8739,  0.6394, -0.0312,  ..., -0.5372,  0.8970,  0.6801]],\n",
       " \n",
       "          [[ 0.8528,  0.8219,  0.9977,  ...,  0.4217, -0.6559, -0.7013],\n",
       "           [-0.6065, -0.9759,  0.7580,  ...,  1.0000,  0.3101, -0.5588],\n",
       "           [-0.8222, -0.9643, -0.3722,  ...,  0.8085, -0.1479, -0.6362],\n",
       "           ...,\n",
       "           [ 0.4668,  0.6277, -0.3981,  ...,  0.5432, -0.4677,  0.7854],\n",
       "           [-0.1316, -0.8218,  0.2806,  ..., -0.0833,  0.4696, -1.0000],\n",
       "           [-0.8382, -0.7655,  0.3975,  ..., -0.8067,  0.9864,  1.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0000, -0.0350,  0.0873,  ...,  0.6726,  0.0550,  0.9955],\n",
       "           [-0.7702,  0.9669,  0.0841,  ..., -0.3916, -1.0000,  0.8103],\n",
       "           [ 0.8972,  0.3759,  0.9640,  ...,  0.8532,  0.4732,  0.4077],\n",
       "           ...,\n",
       "           [-0.9614,  0.8568, -0.1316,  ...,  0.8000, -0.0678, -0.2610],\n",
       "           [ 0.9004, -0.8744, -0.8286,  ..., -0.0077,  1.0000, -0.9997],\n",
       "           [-0.0486,  0.9923,  0.8962,  ..., -0.7535,  0.8676,  0.6578]],\n",
       " \n",
       "          [[-0.9228, -0.4604, -0.4538,  ...,  0.5021, -1.0000,  0.2160],\n",
       "           [ 0.4779, -0.6878,  0.2283,  ..., -0.3678, -0.9389,  0.4759],\n",
       "           [ 0.5242,  1.0000, -0.5179,  ..., -0.9980, -0.7812,  0.6536],\n",
       "           ...,\n",
       "           [-0.2424,  0.3751, -0.3967,  ..., -0.1256,  0.0073, -0.6149],\n",
       "           [-0.3527,  0.5005, -0.8822,  ..., -0.7543, -0.6387,  0.7544],\n",
       "           [-0.1792,  0.3857, -0.3887,  ..., -0.6759,  0.9885, -0.7551]],\n",
       " \n",
       "          [[ 0.8727,  0.1902, -0.2042,  ...,  0.6648, -0.8195,  1.0000],\n",
       "           [-0.8195, -0.4436,  0.9457,  ..., -0.0700,  0.8350, -0.9776],\n",
       "           [ 0.8202, -1.0000,  0.8344,  ..., -0.3740,  0.9152,  0.9939],\n",
       "           ...,\n",
       "           [-0.6082,  0.2984, -0.9291,  ..., -0.9830, -0.6940, -0.3020],\n",
       "           [ 0.1518,  0.9985,  0.3133,  ...,  0.8790,  0.9275,  0.5357],\n",
       "           [-0.9993,  0.1830, -0.9560,  ...,  0.4448,  0.4091, -0.9951]]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[[-4.8643e-01, -2.0745e+00, -1.4788e+00,  ...,  6.4288e-01,\n",
       "             6.0240e-01, -5.9190e-01],\n",
       "           [-4.8993e-01, -8.1220e-01, -1.3652e-01,  ...,  1.2558e-01,\n",
       "             1.5388e+00, -6.8065e-01],\n",
       "           [-1.9229e+00, -1.0334e+00,  3.2612e-02,  ...,  1.0823e+00,\n",
       "             4.3583e-01, -9.9754e-01],\n",
       "           ...,\n",
       "           [-2.4772e-01,  3.1325e+00,  4.0815e-01,  ...,  2.2405e-01,\n",
       "            -3.3617e-01,  6.7280e-01],\n",
       "           [-6.3481e-01,  7.9799e-01, -1.6240e-01,  ...,  8.5391e-01,\n",
       "            -9.3421e-02,  6.5245e-01],\n",
       "           [-1.0084e-01,  1.3326e+00, -8.8908e-02,  ...,  1.1495e+00,\n",
       "            -1.9023e+00,  1.2656e+00]],\n",
       " \n",
       "          [[ 8.4572e-01,  6.7457e-01, -2.0062e+00,  ...,  4.2666e-01,\n",
       "            -7.9229e-01, -5.2352e-01],\n",
       "           [-1.0020e+00, -3.7870e-01, -3.7656e-01,  ..., -5.0105e-01,\n",
       "             2.3867e-01, -1.7510e+00],\n",
       "           [ 7.2585e-01, -7.9366e-01,  1.2381e+00,  ..., -5.6516e-01,\n",
       "             1.8429e+00,  1.4327e+00],\n",
       "           ...,\n",
       "           [-1.6811e+00, -5.9884e-01,  1.1674e+00,  ...,  1.0462e+00,\n",
       "             2.0364e-01, -2.7579e+00],\n",
       "           [-9.6337e-01, -3.8487e-01,  2.0203e+00,  ..., -6.8453e-03,\n",
       "             7.0967e-01,  6.1890e-01],\n",
       "           [-7.4267e-01, -7.4729e-01,  1.1729e+00,  ...,  1.8043e+00,\n",
       "            -1.1242e-01, -5.9332e-01]],\n",
       " \n",
       "          [[ 7.6640e-02,  1.0886e+00,  1.4744e+00,  ...,  1.5389e-01,\n",
       "             1.5191e+00,  1.8628e+00],\n",
       "           [-1.5136e-01, -8.4742e-01,  7.2788e-01,  ..., -8.7813e-01,\n",
       "             9.6102e-01,  7.2600e-01],\n",
       "           [ 2.1614e-01, -2.3274e-01, -7.7994e-03,  ...,  3.6619e-01,\n",
       "            -1.6698e+00,  8.8602e-06],\n",
       "           ...,\n",
       "           [-9.3256e-01, -3.5446e-01,  2.2081e+00,  ...,  1.2175e+00,\n",
       "             1.3315e+00,  4.3912e-01],\n",
       "           [ 1.1212e+00,  2.0798e+00, -8.5785e-01,  ...,  1.0277e+00,\n",
       "             7.3665e-01, -4.2031e-01],\n",
       "           [-1.9236e+00, -1.7296e+00,  1.0399e+00,  ...,  8.0675e-01,\n",
       "            -9.7981e-01, -1.4934e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6947e+00, -8.5110e-01, -2.2706e+00,  ..., -1.0515e+00,\n",
       "             4.6516e-02, -8.6159e-01],\n",
       "           [ 1.8444e+00, -1.4867e+00,  6.0275e-01,  ..., -1.0663e-01,\n",
       "            -2.0748e-01,  1.2496e+00],\n",
       "           [-8.2029e-01,  4.5549e-02,  9.8323e-02,  ..., -2.4309e+00,\n",
       "             8.7762e-01,  7.9375e-01],\n",
       "           ...,\n",
       "           [-5.5355e-02,  4.9556e-01,  9.3519e-01,  ..., -3.3279e-01,\n",
       "            -8.1701e-02,  1.2357e+00],\n",
       "           [-6.5755e-01, -2.0345e+00, -8.3914e-01,  ...,  1.1502e+00,\n",
       "            -3.8022e-01,  9.4418e-01],\n",
       "           [ 2.4260e+00,  9.1808e-01, -2.9345e-01,  ..., -6.5197e-01,\n",
       "             1.0876e-01, -2.6172e-01]],\n",
       " \n",
       "          [[ 1.7460e+00,  1.4338e-01,  2.0470e-01,  ...,  1.1368e-01,\n",
       "             1.5613e+00, -7.4367e-01],\n",
       "           [ 1.2575e+00, -4.4618e-01, -1.7560e+00,  ...,  2.7729e-01,\n",
       "            -4.5370e-01,  2.4852e+00],\n",
       "           [ 5.1037e-01, -6.0695e-01, -4.1165e-01,  ...,  8.8147e-01,\n",
       "            -1.2171e+00, -6.9765e-01],\n",
       "           ...,\n",
       "           [ 1.6439e+00, -2.7477e-01, -9.7038e-01,  ..., -1.4683e+00,\n",
       "             1.3611e+00, -5.0454e-01],\n",
       "           [-2.2621e-01,  4.5660e-01, -1.1480e+00,  ..., -2.0588e-01,\n",
       "            -9.6127e-01, -6.1013e-01],\n",
       "           [-2.8379e-01, -7.5117e-01,  1.1580e-01,  ..., -5.7409e-01,\n",
       "             2.6100e-01, -3.9539e-01]],\n",
       " \n",
       "          [[ 4.4403e-01,  9.6286e-01,  7.5032e-01,  ...,  2.9249e-01,\n",
       "             4.6333e-02, -7.4571e-01],\n",
       "           [ 1.0703e-01, -2.1130e-01, -3.7112e-01,  ..., -2.0507e+00,\n",
       "             1.3688e+00, -1.7273e+00],\n",
       "           [ 9.7074e-01, -1.3034e-01,  9.6018e-01,  ..., -1.5903e-01,\n",
       "            -8.1023e-02,  1.2573e+00],\n",
       "           ...,\n",
       "           [ 4.1094e-01,  1.3911e+00, -6.3326e-01,  ...,  5.9461e-01,\n",
       "             3.3098e-01, -6.1542e-01],\n",
       "           [ 2.2057e-01,  5.5912e-01, -2.6839e+00,  ...,  5.0057e-01,\n",
       "             1.1160e+00, -1.8238e-01],\n",
       "           [-6.9774e-01,  1.3587e+00, -6.0503e-02,  ..., -3.9808e-01,\n",
       "            -1.3241e+00, -6.1077e-01]]],\n",
       " \n",
       " \n",
       "         [[[-6.2942e-01,  8.1974e-01,  1.6645e+00,  ..., -4.3288e-01,\n",
       "            -1.2451e+00,  1.0466e+00],\n",
       "           [-1.3971e+00, -6.9972e-01, -4.1966e-01,  ...,  1.6259e-01,\n",
       "            -4.8455e-01,  4.8484e-01],\n",
       "           [ 1.2259e+00, -2.4955e-01, -8.9631e-01,  ..., -6.1337e-01,\n",
       "            -4.1120e-01,  7.0333e-01],\n",
       "           ...,\n",
       "           [-2.1663e-01,  3.0989e-01,  6.8501e-01,  ...,  1.4531e+00,\n",
       "             5.0015e-01,  5.9090e-01],\n",
       "           [ 1.5299e+00,  1.9828e+00,  1.9546e+00,  ...,  4.5691e-02,\n",
       "             7.1607e-01, -4.7402e-01],\n",
       "           [-7.0149e-01,  1.7890e-01,  5.4065e-01,  ...,  6.0355e-02,\n",
       "             1.9562e+00,  6.6653e-01]],\n",
       " \n",
       "          [[ 7.5850e-01,  2.0967e-01, -7.9315e-01,  ...,  5.7545e-01,\n",
       "            -8.0652e-01,  3.8974e-01],\n",
       "           [-1.6141e-01,  1.3266e+00, -1.0246e+00,  ...,  6.6115e-01,\n",
       "            -6.2567e-02, -7.4116e-01],\n",
       "           [ 2.3083e-01,  2.5373e-01,  9.0314e-01,  ..., -9.8875e-01,\n",
       "             5.5307e-01, -7.5521e-01],\n",
       "           ...,\n",
       "           [-8.4884e-01,  7.8867e-02, -1.0709e+00,  ..., -3.9235e-01,\n",
       "            -4.3010e-01,  6.4111e-01],\n",
       "           [-1.6724e+00,  8.7553e-01, -7.1568e-01,  ...,  1.7087e+00,\n",
       "             5.6144e-01,  1.4407e-01],\n",
       "           [ 5.9205e-01,  2.3617e+00,  8.7157e-02,  ..., -6.3287e-01,\n",
       "             2.1782e-01,  2.7013e-01]],\n",
       " \n",
       "          [[ 2.0466e-01,  2.3473e+00, -3.2778e-01,  ...,  2.1451e+00,\n",
       "             4.0280e-01,  5.7180e-02],\n",
       "           [-1.0866e+00,  4.9999e-02, -8.5628e-01,  ...,  4.9450e-01,\n",
       "            -1.3617e+00, -1.7392e+00],\n",
       "           [-8.0211e-01, -1.8199e-01, -1.8437e-01,  ...,  5.7392e-01,\n",
       "             1.0692e-01,  4.4233e-01],\n",
       "           ...,\n",
       "           [-1.5121e+00,  5.0333e-02,  1.6856e+00,  ...,  1.1835e+00,\n",
       "             4.9838e-01,  1.7363e-01],\n",
       "           [-2.1415e-01,  9.2647e-02,  1.5211e+00,  ..., -7.5688e-01,\n",
       "             3.4295e+00, -1.7457e-01],\n",
       "           [-4.9667e-01, -1.3146e+00,  9.7621e-02,  ..., -1.0795e+00,\n",
       "            -1.3337e+00, -6.0237e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.3314e+00, -3.1544e-01,  1.7600e+00,  ...,  1.1262e-01,\n",
       "             8.7037e-03, -4.8570e-01],\n",
       "           [ 1.5844e+00,  1.3780e+00, -1.8531e-01,  ...,  7.5914e-01,\n",
       "             7.8753e-01,  2.1660e+00],\n",
       "           [-8.8951e-01, -5.0620e-01, -3.0276e-01,  ...,  4.9969e-02,\n",
       "            -2.5011e-01,  7.3578e-01],\n",
       "           ...,\n",
       "           [ 2.0972e-01,  9.3773e-02,  3.7127e-01,  ..., -5.3502e-01,\n",
       "            -4.7624e-01,  7.8816e-01],\n",
       "           [ 1.6621e+00,  1.0223e+00, -5.7278e-02,  ...,  9.2958e-01,\n",
       "             1.2622e+00,  8.0387e-01],\n",
       "           [ 3.4461e-01, -2.7825e+00,  3.0393e-01,  ...,  1.8636e-01,\n",
       "            -7.7060e-01,  2.3129e-01]],\n",
       " \n",
       "          [[ 3.4948e-01, -1.1139e+00,  9.7053e-01,  ..., -1.7460e-02,\n",
       "             1.9621e+00, -6.8077e-02],\n",
       "           [ 1.4414e-01, -9.6574e-01,  1.5865e+00,  ...,  3.6155e-01,\n",
       "            -4.3206e-01, -1.7661e-01],\n",
       "           [-1.5290e+00,  1.9827e+00,  8.6296e-01,  ...,  1.1947e+00,\n",
       "             1.8246e+00, -2.1625e+00],\n",
       "           ...,\n",
       "           [ 8.3032e-01, -1.4628e+00, -8.7996e-02,  ...,  1.7926e+00,\n",
       "            -8.2665e-01, -6.7242e-01],\n",
       "           [-1.5648e+00, -6.5313e-01, -6.1058e-03,  ...,  1.8558e+00,\n",
       "            -4.7141e-01, -1.0333e+00],\n",
       "           [ 2.3826e-02, -2.6022e+00, -7.0244e-02,  ..., -2.7272e-01,\n",
       "            -5.1522e-02,  9.5180e-01]],\n",
       " \n",
       "          [[ 5.0253e-01, -1.2323e+00, -1.2195e+00,  ...,  3.7418e-01,\n",
       "             1.9675e+00,  4.9686e-01],\n",
       "           [-1.0477e+00,  1.1654e+00,  9.1225e-01,  ..., -2.2388e-01,\n",
       "            -2.2077e+00,  8.6045e-01],\n",
       "           [-8.6563e-01, -1.4589e+00,  1.0821e+00,  ..., -2.6650e-01,\n",
       "             9.3781e-01, -9.9039e-01],\n",
       "           ...,\n",
       "           [-8.1234e-01,  4.4804e-01,  6.5073e-01,  ...,  8.3707e-01,\n",
       "            -6.9357e-01,  1.6930e+00],\n",
       "           [ 1.1774e+00,  2.6996e-01,  8.3081e-01,  ...,  9.9854e-01,\n",
       "            -1.9230e-01,  3.4371e-01],\n",
       "           [ 3.9887e-01,  1.3198e+00,  4.8470e-01,  ...,  1.7964e-01,\n",
       "            -4.1267e-01,  6.8619e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.6409e+00,  2.0132e+00,  1.1908e+00,  ..., -2.8432e-01,\n",
       "            -1.9595e+00, -1.2144e-01],\n",
       "           [-1.9314e-01,  4.9651e-01,  3.6274e-01,  ...,  5.8344e-01,\n",
       "             1.7616e-01,  2.8504e-01],\n",
       "           [ 1.8557e+00, -4.3682e-01,  2.8451e-01,  ..., -7.5098e-01,\n",
       "             3.9246e-01, -1.3803e+00],\n",
       "           ...,\n",
       "           [ 4.2241e-01, -1.7763e+00, -3.0190e-01,  ...,  3.4675e-01,\n",
       "            -3.6829e+00,  7.7602e-01],\n",
       "           [ 3.8799e-01, -1.9367e-01,  2.0755e+00,  ...,  8.3319e-01,\n",
       "             2.4003e-03, -1.3646e-01],\n",
       "           [-9.3259e-03, -3.2371e-01,  4.2892e-01,  ..., -2.0769e-01,\n",
       "            -4.8781e-01,  3.5118e-01]],\n",
       " \n",
       "          [[ 2.4191e+00, -6.5562e-01,  8.4233e-01,  ..., -1.5391e+00,\n",
       "             3.0900e-01, -1.1080e+00],\n",
       "           [ 2.9287e-01,  1.4917e-01, -2.8431e-01,  ...,  4.9036e-01,\n",
       "             1.1965e+00, -2.0738e-01],\n",
       "           [ 1.7313e-01, -6.9978e-02, -5.9106e-01,  ...,  2.4259e-01,\n",
       "            -1.1204e+00,  1.6280e+00],\n",
       "           ...,\n",
       "           [ 5.2531e-01,  1.6356e-01, -1.7092e+00,  ...,  1.5123e+00,\n",
       "             5.0587e-01,  3.0064e-01],\n",
       "           [-6.7792e-01, -2.6856e-02, -2.0832e+00,  ...,  8.4680e-01,\n",
       "             2.1435e-01,  9.4829e-01],\n",
       "           [-1.3279e+00, -1.0311e+00,  1.0660e-01,  ..., -1.6852e+00,\n",
       "             7.9764e-02, -2.4874e-01]],\n",
       " \n",
       "          [[-4.4613e-01,  5.5844e-01, -1.4307e+00,  ..., -1.2419e-01,\n",
       "            -2.0843e-01, -5.6811e-01],\n",
       "           [ 6.2405e-01,  3.0504e-01, -2.0826e+00,  ...,  1.4512e+00,\n",
       "            -3.7323e-01,  6.5763e-01],\n",
       "           [ 8.5096e-01,  5.9672e-01,  1.1998e-01,  ..., -4.7675e-01,\n",
       "            -6.9730e-01, -1.9426e+00],\n",
       "           ...,\n",
       "           [ 1.6442e+00, -8.9772e-01, -4.8861e-01,  ...,  1.3876e+00,\n",
       "             1.8397e+00, -1.2135e-01],\n",
       "           [-3.3695e-01,  1.9446e+00, -1.1287e+00,  ...,  6.3680e-01,\n",
       "             7.2561e-01,  9.8608e-01],\n",
       "           [ 2.4823e-01,  7.4950e-01, -1.1264e+00,  ...,  1.8885e+00,\n",
       "            -9.8586e-01, -1.7246e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.2001e-01, -1.3444e+00,  1.4407e+00,  ...,  6.5566e-01,\n",
       "             4.2081e-02,  1.3543e+00],\n",
       "           [ 1.1236e+00,  8.4777e-01, -2.0585e+00,  ..., -4.6155e-01,\n",
       "             1.6249e+00,  4.3758e-01],\n",
       "           [ 1.1695e+00,  7.9003e-01, -6.5953e-01,  ..., -1.6437e-01,\n",
       "             1.0097e+00,  1.2424e+00],\n",
       "           ...,\n",
       "           [ 6.0013e-01,  7.5247e-03, -1.2909e+00,  ..., -5.9574e-01,\n",
       "            -9.7890e-01, -6.0605e-01],\n",
       "           [-1.7148e+00, -1.2694e+00,  1.2214e+00,  ..., -6.7458e-01,\n",
       "            -7.4274e-01,  8.1734e-01],\n",
       "           [ 1.0258e+00, -1.5571e+00,  2.9695e-01,  ...,  1.2332e+00,\n",
       "             3.2012e-01,  1.9239e-01]],\n",
       " \n",
       "          [[-2.1784e+00, -1.0934e+00,  7.9439e-02,  ...,  3.6438e-01,\n",
       "            -1.4367e+00,  1.1408e+00],\n",
       "           [ 4.3471e-01, -1.6971e+00,  9.5948e-02,  ...,  5.0401e-01,\n",
       "            -1.5936e+00,  9.7748e-01],\n",
       "           [ 9.8812e-01, -1.4480e+00, -4.2050e-01,  ..., -9.9815e-01,\n",
       "             1.7501e+00,  3.2953e-01],\n",
       "           ...,\n",
       "           [-1.2875e+00,  8.9506e-01, -1.6622e-01,  ..., -1.1273e+00,\n",
       "            -7.7813e-02,  4.0063e-01],\n",
       "           [-7.1981e-01,  5.2602e-01, -1.8056e+00,  ...,  6.7683e-01,\n",
       "            -1.4516e-01,  9.2879e-01],\n",
       "           [ 6.1139e-01,  5.7867e-01,  5.6754e-01,  ..., -1.0250e+00,\n",
       "            -1.2171e-01,  1.8395e-01]],\n",
       " \n",
       "          [[-2.0748e+00,  7.7769e-01, -1.2017e-01,  ..., -1.0234e+00,\n",
       "             9.2991e-01, -4.1689e-01],\n",
       "           [ 8.2377e-01,  8.1852e-01,  8.4875e-01,  ..., -2.1593e+00,\n",
       "             6.5483e-01,  1.1089e+00],\n",
       "           [ 8.1597e-01, -3.8630e-01, -1.7080e+00,  ...,  8.7889e-01,\n",
       "             6.5741e-01, -3.3332e-01],\n",
       "           ...,\n",
       "           [ 8.2054e-01,  1.0294e+00,  2.1163e+00,  ...,  5.6989e-02,\n",
       "            -1.0740e+00, -5.5703e-01],\n",
       "           [ 1.4816e+00,  8.4299e-01, -4.8231e-01,  ..., -1.7537e+00,\n",
       "            -3.1276e-01, -4.8991e-01],\n",
       "           [-1.4589e+00, -1.2215e-01,  6.4499e-02,  ..., -7.3717e-01,\n",
       "            -9.7542e-01,  1.2834e+00]]],\n",
       " \n",
       " \n",
       "         [[[-7.9665e-01, -1.4540e+00, -3.6292e-02,  ..., -1.6592e+00,\n",
       "             3.3774e-01, -1.9991e+00],\n",
       "           [ 5.1832e-01, -3.9284e-01, -9.9230e-01,  ...,  2.2728e-01,\n",
       "            -1.5506e+00,  3.0316e-02],\n",
       "           [ 4.7643e-01, -1.2221e-01,  8.8220e-01,  ...,  3.3429e-01,\n",
       "            -5.0394e-01, -1.6596e+00],\n",
       "           ...,\n",
       "           [ 4.9358e-01, -1.2124e-01, -2.4848e-01,  ..., -3.9398e-01,\n",
       "             1.2288e+00, -1.4893e+00],\n",
       "           [-2.1235e+00, -5.9323e-01, -6.9234e-01,  ...,  4.2938e-01,\n",
       "            -4.8752e-01,  3.0972e-01],\n",
       "           [ 8.2966e-01,  6.1145e-01, -2.5102e-01,  ..., -1.2378e+00,\n",
       "            -9.8720e-01,  8.1052e-01]],\n",
       " \n",
       "          [[-5.4439e-01,  6.5004e-01,  4.4627e-01,  ...,  4.5090e-01,\n",
       "            -1.4377e+00,  1.4114e+00],\n",
       "           [-1.1579e+00, -7.5832e-01,  1.7865e+00,  ..., -6.2717e-01,\n",
       "            -6.0345e-01,  1.4016e-01],\n",
       "           [ 1.0464e+00, -8.0748e-01,  1.7646e-01,  ...,  8.1596e-01,\n",
       "             1.4408e+00, -3.1429e-01],\n",
       "           ...,\n",
       "           [ 5.2023e-01,  1.8104e+00,  2.5409e-01,  ..., -4.8272e-01,\n",
       "             9.8212e-01,  3.4295e-01],\n",
       "           [-3.2436e-01,  3.8055e-01, -9.3624e-01,  ...,  5.1583e-01,\n",
       "             7.3264e-01, -1.7599e+00],\n",
       "           [-5.0114e-01, -1.0861e-01,  9.8019e-01,  ..., -9.6574e-01,\n",
       "             1.6455e-01,  1.2593e+00]],\n",
       " \n",
       "          [[ 3.2596e-01,  1.3091e+00, -6.1395e-01,  ...,  3.3652e-01,\n",
       "             2.9824e-01,  3.9514e-01],\n",
       "           [-1.4479e+00, -4.2532e-01,  7.1457e-01,  ...,  2.3998e+00,\n",
       "            -9.3389e-01,  9.4371e-01],\n",
       "           [ 7.1617e-01,  5.5313e-01,  6.1483e-01,  ...,  1.5985e+00,\n",
       "            -1.8636e-01, -6.4184e-01],\n",
       "           ...,\n",
       "           [ 9.3749e-01, -1.5162e+00,  6.3383e-02,  ...,  7.8749e-01,\n",
       "            -6.4385e-01,  4.6130e-01],\n",
       "           [ 8.1403e-01, -1.0043e+00, -1.4377e-01,  ..., -1.0747e-01,\n",
       "             7.2540e-01,  2.3799e+00],\n",
       "           [ 3.5058e+00,  9.7704e-01,  1.0716e+00,  ..., -1.6676e-01,\n",
       "            -7.4109e-01, -1.2000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0483e+00, -1.0465e+00, -1.7134e+00,  ..., -3.2292e+00,\n",
       "             1.6456e+00,  3.8469e-01],\n",
       "           [ 1.5539e+00,  3.1714e-01, -1.7977e-01,  ...,  4.7368e-02,\n",
       "            -4.5877e-02,  1.7046e-01],\n",
       "           [-3.7251e-01,  9.0779e-01,  4.8621e-01,  ...,  5.2021e-01,\n",
       "             9.9009e-02,  7.7908e-01],\n",
       "           ...,\n",
       "           [ 1.2411e+00,  1.6406e+00,  6.8039e-01,  ..., -3.1195e-01,\n",
       "            -1.3522e+00, -6.9180e-01],\n",
       "           [-1.2747e+00, -1.2855e+00, -8.9329e-01,  ...,  1.7446e+00,\n",
       "            -6.9154e-01, -1.0269e+00],\n",
       "           [-1.1466e+00, -4.9632e-01,  5.0880e-02,  ..., -1.0418e+00,\n",
       "            -2.0151e+00, -1.5957e+00]],\n",
       " \n",
       "          [[ 6.1418e-01, -3.7828e-01, -7.1582e-01,  ...,  3.0947e-01,\n",
       "            -5.7972e-01, -7.9235e-01],\n",
       "           [-5.1876e-01, -9.3498e-02,  7.2356e-01,  ..., -2.6774e-01,\n",
       "             1.0118e+00, -2.1273e+00],\n",
       "           [-2.5923e-01, -1.3084e-01, -1.2384e+00,  ..., -9.7035e-01,\n",
       "            -3.9471e-01,  2.6122e+00],\n",
       "           ...,\n",
       "           [-1.2698e+00, -8.3873e-01, -2.7938e-01,  ...,  4.3481e-02,\n",
       "             1.7424e+00, -9.4567e-01],\n",
       "           [ 4.4793e-01, -2.9236e-01, -1.1642e-01,  ...,  8.1884e-01,\n",
       "            -4.4658e-01,  2.7345e-01],\n",
       "           [-1.8489e+00,  3.7677e-01,  7.3484e-01,  ..., -3.5677e-03,\n",
       "             1.0768e+00, -3.4448e-01]],\n",
       " \n",
       "          [[-2.0056e+00,  8.6572e-02, -3.2080e-01,  ...,  1.4964e-01,\n",
       "            -1.9157e+00,  1.2717e+00],\n",
       "           [ 2.5470e+00,  1.4925e-02,  1.3567e+00,  ...,  1.7917e+00,\n",
       "             2.4472e+00,  1.5280e+00],\n",
       "           [-9.3699e-01,  1.3281e+00, -4.9316e-01,  ..., -4.0302e-01,\n",
       "            -2.0693e-01,  4.2354e-01],\n",
       "           ...,\n",
       "           [-5.6274e-01,  7.7129e-01, -1.6824e+00,  ...,  1.3982e+00,\n",
       "            -1.5203e+00,  1.6448e+00],\n",
       "           [ 1.7885e-01,  1.8096e+00, -1.1075e+00,  ..., -3.0352e-01,\n",
       "            -5.6071e-01, -1.1341e+00],\n",
       "           [ 9.9902e-01, -8.1890e-01,  4.1273e-01,  ...,  4.5300e-01,\n",
       "             5.0517e-01,  2.1973e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 8.5094e-01,  5.3693e-02, -2.5520e-01,  ...,  1.2311e+00,\n",
       "             9.2796e-01,  9.5301e-01],\n",
       "           [-2.9287e-01, -2.3410e-01, -8.3136e-01,  ..., -1.1257e+00,\n",
       "             7.2772e-01, -1.0975e+00],\n",
       "           [-8.8004e-01, -8.8902e-01, -1.3359e-01,  ...,  1.4546e+00,\n",
       "             1.2969e+00,  1.6646e-02],\n",
       "           ...,\n",
       "           [-1.6186e+00, -2.9423e+00, -7.6073e-01,  ..., -1.8363e-01,\n",
       "            -7.6067e-02, -1.4990e-01],\n",
       "           [ 1.0804e+00, -1.0374e+00, -1.0228e-01,  ..., -2.8314e-01,\n",
       "             1.0843e-01,  7.9317e-01],\n",
       "           [-7.5085e-01, -8.7846e-01, -7.1268e-01,  ..., -3.1412e-01,\n",
       "             1.4343e+00,  1.8991e-01]],\n",
       " \n",
       "          [[ 1.1070e+00,  1.4329e+00,  7.0560e-01,  ..., -8.0177e-01,\n",
       "            -5.3194e-01,  1.9343e-01],\n",
       "           [-1.7973e+00, -1.9435e+00,  3.6933e-01,  ...,  6.8004e-03,\n",
       "             6.9074e-01, -1.5477e-01],\n",
       "           [-2.4550e-02,  6.1518e-01, -1.1473e+00,  ..., -6.3521e-01,\n",
       "            -2.2892e+00, -1.1236e+00],\n",
       "           ...,\n",
       "           [-6.3903e-01,  1.1625e+00, -1.0341e+00,  ...,  4.8722e-01,\n",
       "            -8.3012e-01, -5.4767e-01],\n",
       "           [-4.4296e-01, -1.6324e+00,  1.1576e-01,  ...,  4.5332e-01,\n",
       "            -1.4221e-01, -4.1369e-01],\n",
       "           [ 1.6444e-01,  1.8162e-01,  1.1377e+00,  ...,  2.6702e+00,\n",
       "            -1.2978e+00, -8.5687e-01]],\n",
       " \n",
       "          [[ 1.0192e+00, -4.1634e-01,  9.0315e-01,  ...,  3.9024e-01,\n",
       "            -1.3059e+00,  1.9024e+00],\n",
       "           [ 1.9554e-01, -2.3207e-01,  9.6968e-02,  ...,  1.1233e-02,\n",
       "             4.6835e-01, -3.1964e-01],\n",
       "           [ 1.4794e+00, -8.5304e-01, -1.8764e+00,  ..., -4.7460e-01,\n",
       "            -1.5103e+00,  9.3916e-01],\n",
       "           ...,\n",
       "           [-3.3350e-01,  6.6010e-01,  1.3419e-01,  ..., -1.9372e+00,\n",
       "            -1.4218e+00, -8.3047e-01],\n",
       "           [-4.1991e-01, -5.8306e-01,  6.7932e-01,  ...,  5.7797e-01,\n",
       "            -6.7727e-01, -2.5720e-01],\n",
       "           [-3.4833e-01,  1.7431e+00,  1.6006e-02,  ...,  3.5861e-02,\n",
       "            -8.2988e-01,  5.4219e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2746e+00, -1.1707e+00,  1.4748e+00,  ..., -5.7329e-01,\n",
       "             5.3282e-01,  2.1956e+00],\n",
       "           [-8.4629e-01, -1.4970e+00, -1.5319e+00,  ..., -2.2893e+00,\n",
       "             6.3030e-01,  1.6545e-01],\n",
       "           [ 1.5028e+00,  7.9681e-01,  1.7011e+00,  ..., -1.6477e+00,\n",
       "             9.5734e-01,  1.1666e+00],\n",
       "           ...,\n",
       "           [ 4.7367e-01,  3.3405e-01,  1.2446e-02,  ...,  1.3025e+00,\n",
       "             5.2931e-01,  1.6087e+00],\n",
       "           [ 3.0589e-01,  4.7799e-01, -2.0592e-01,  ..., -6.2058e-01,\n",
       "            -9.4395e-01, -2.6007e-01],\n",
       "           [ 1.9900e+00, -1.0890e+00, -3.2714e-01,  ...,  1.2813e+00,\n",
       "             9.2297e-01,  1.6654e-01]],\n",
       " \n",
       "          [[ 7.6512e-01, -9.8097e-01,  8.7612e-01,  ..., -2.0254e-01,\n",
       "             8.6566e-01, -2.2238e-01],\n",
       "           [ 1.3932e+00, -3.1662e-01, -1.1104e+00,  ..., -2.5350e-01,\n",
       "             1.1034e+00,  4.5502e-01],\n",
       "           [-2.3285e-01,  3.3924e-02, -1.2558e+00,  ...,  6.0332e-01,\n",
       "            -1.0974e+00, -1.0200e+00],\n",
       "           ...,\n",
       "           [ 6.8057e-01, -7.0300e-02, -7.0425e-01,  ..., -9.5109e-01,\n",
       "            -2.2723e+00, -1.1573e+00],\n",
       "           [-4.1446e-01, -1.4117e-02, -5.0434e-01,  ..., -4.2556e-01,\n",
       "            -3.1973e-01, -4.4042e-01],\n",
       "           [ 2.5980e-02,  6.6237e-01,  4.8466e-01,  ...,  6.5228e-02,\n",
       "            -7.4891e-01,  9.5018e-01]],\n",
       " \n",
       "          [[-6.5118e-01,  6.6677e-01, -6.3193e-01,  ..., -2.0640e+00,\n",
       "             5.9455e-01, -8.4148e-01],\n",
       "           [-4.9438e-01, -6.0067e-01,  1.0889e+00,  ...,  5.7336e-01,\n",
       "             1.1674e-01,  2.0224e-01],\n",
       "           [-3.2188e-01, -5.6452e-01, -4.0363e-01,  ...,  3.9035e-01,\n",
       "            -7.9955e-01, -5.8612e-01],\n",
       "           ...,\n",
       "           [ 6.0709e-01,  1.3501e-01, -4.2798e-02,  ..., -2.5847e-01,\n",
       "             6.8805e-01,  1.2431e+00],\n",
       "           [ 6.8681e-01,  1.3920e-01, -1.1772e+00,  ..., -1.0656e+00,\n",
       "             1.4094e-01,  6.3159e-01],\n",
       "           [-9.3209e-01, -6.6938e-01, -6.9183e-02,  ...,  4.6821e-01,\n",
       "            -3.6279e-01, -8.8446e-01]]],\n",
       " \n",
       " \n",
       "         [[[-9.2092e-01, -9.5996e-01,  9.4858e-01,  ...,  1.8580e-01,\n",
       "             3.5015e-01, -4.0892e-01],\n",
       "           [ 2.8419e-02, -2.1997e-01, -5.6834e-01,  ...,  4.3519e-01,\n",
       "             8.9670e-01, -1.8014e-01],\n",
       "           [ 3.1845e-01, -8.6954e-01, -6.3316e-01,  ...,  1.0312e+00,\n",
       "            -4.2453e-01,  7.4470e-01],\n",
       "           ...,\n",
       "           [-5.1230e-01, -6.2554e-01,  1.0193e+00,  ..., -1.1894e+00,\n",
       "            -2.1183e+00, -4.8615e-01],\n",
       "           [-6.8293e-02,  2.1040e+00,  1.1504e+00,  ..., -3.4767e-01,\n",
       "            -1.0288e+00,  4.6654e-01],\n",
       "           [ 6.0983e-01,  2.8436e-01,  1.7901e+00,  ...,  3.6254e-01,\n",
       "             6.1945e-01, -1.4819e+00]],\n",
       " \n",
       "          [[-6.6370e-01,  3.3270e-01, -4.3950e-01,  ...,  2.1124e+00,\n",
       "             1.6868e+00,  3.6952e-01],\n",
       "           [ 1.4821e-01, -6.8904e-01,  1.2806e+00,  ...,  7.9651e-01,\n",
       "             8.3062e-01,  6.8007e-01],\n",
       "           [ 6.2213e-02, -1.4992e+00,  1.2542e+00,  ..., -3.6342e-01,\n",
       "            -2.7738e-01,  5.7132e-01],\n",
       "           ...,\n",
       "           [ 1.4072e+00,  9.7005e-01, -6.4380e-02,  ..., -1.2861e-01,\n",
       "             2.9718e-01,  4.4689e-01],\n",
       "           [ 2.2731e+00,  4.8597e-01,  3.5592e-01,  ..., -8.2883e-01,\n",
       "             5.0800e-01,  1.1439e+00],\n",
       "           [-1.9981e+00,  9.5374e-02, -1.5468e+00,  ..., -1.9821e-01,\n",
       "            -9.2016e-01, -7.3368e-01]],\n",
       " \n",
       "          [[ 7.0686e-01,  5.4167e-01,  1.4162e+00,  ...,  9.2660e-01,\n",
       "            -1.0375e-01, -2.3523e+00],\n",
       "           [ 2.7665e-01,  1.3417e+00,  4.4315e-02,  ...,  1.6185e+00,\n",
       "             6.4816e-01, -6.1439e-01],\n",
       "           [ 7.3944e-01,  9.1508e-01, -2.9445e-01,  ..., -2.5951e+00,\n",
       "             4.3671e-01, -1.7656e+00],\n",
       "           ...,\n",
       "           [-1.9722e-01, -6.6496e-01, -1.1250e+00,  ...,  1.5448e+00,\n",
       "             5.1870e-01,  8.1215e-01],\n",
       "           [-2.4498e-01, -3.7367e-01,  9.4708e-01,  ..., -1.1751e+00,\n",
       "            -1.3185e+00, -1.8783e+00],\n",
       "           [-1.4608e+00, -1.0930e+00, -1.3956e+00,  ...,  6.5589e-01,\n",
       "            -6.2460e-01,  2.7534e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.3717e-01, -4.6717e-01,  1.8537e+00,  ...,  9.8520e-02,\n",
       "            -1.1031e+00, -5.5841e-01],\n",
       "           [-6.8949e-01,  3.9504e-01,  8.0917e-01,  ..., -5.8856e-01,\n",
       "             1.7613e+00,  8.9719e-01],\n",
       "           [-1.5954e+00, -3.3788e-01,  7.4098e-01,  ...,  1.4773e+00,\n",
       "            -1.1899e+00, -5.2519e-01],\n",
       "           ...,\n",
       "           [ 1.2537e+00, -2.0601e+00,  1.2797e+00,  ...,  1.1112e-01,\n",
       "            -2.6039e-01,  4.5026e-01],\n",
       "           [ 5.7534e-01,  1.0807e-01,  1.3867e+00,  ...,  1.3148e+00,\n",
       "             3.7297e-01,  5.3212e-01],\n",
       "           [ 2.2616e-01,  5.4252e-02,  7.0716e-01,  ...,  1.3114e+00,\n",
       "            -4.9468e-01, -2.5740e-01]],\n",
       " \n",
       "          [[-5.2403e-01, -1.0675e+00, -8.5368e-01,  ..., -1.0819e+00,\n",
       "            -4.4446e-01,  1.7182e-01],\n",
       "           [ 1.2920e+00,  7.1684e-01,  1.1779e+00,  ...,  1.6327e+00,\n",
       "            -9.0590e-01, -6.7029e-01],\n",
       "           [ 6.4923e-01, -1.4792e+00, -6.6499e-01,  ..., -1.0505e+00,\n",
       "            -4.3437e-01, -2.0640e-01],\n",
       "           ...,\n",
       "           [ 4.1276e-01, -2.5454e+00, -1.4663e+00,  ...,  1.7538e+00,\n",
       "             9.5836e-01,  1.0419e+00],\n",
       "           [-1.9145e-01, -7.6890e-01, -7.9688e-01,  ..., -9.4647e-01,\n",
       "            -4.8167e-01,  8.6093e-02],\n",
       "           [-4.2624e-01, -5.9120e-01, -8.1090e-01,  ...,  2.1789e-01,\n",
       "            -2.3021e-01,  3.5087e-01]],\n",
       " \n",
       "          [[-5.8058e-02,  4.5522e-01, -1.4565e-01,  ...,  1.1192e+00,\n",
       "            -2.5996e-01,  1.0413e+00],\n",
       "           [-1.0727e+00, -7.3888e-01,  2.9253e-01,  ..., -6.2770e-01,\n",
       "            -2.0607e-01, -2.2788e-02],\n",
       "           [-1.6558e+00,  8.6840e-01,  5.1643e-01,  ..., -5.9740e-01,\n",
       "            -1.0540e-01,  1.8251e+00],\n",
       "           ...,\n",
       "           [-5.2372e-01,  4.4423e-01, -1.1535e+00,  ..., -3.0417e-01,\n",
       "            -1.0564e+00, -2.1498e+00],\n",
       "           [ 2.8359e-01, -5.4177e-01, -1.3669e+00,  ...,  6.4080e-01,\n",
       "             2.3668e-01,  1.6004e-01],\n",
       "           [ 4.3916e-01, -5.3961e-01, -7.6018e-01,  ..., -6.6752e-01,\n",
       "            -1.8840e-01, -1.5664e+00]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.to('cuda')\n",
    "diffusion.ddim_sampler(y_cond=torch.randn(6, 256, 200, 200, device='cuda'), steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74bb0781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "UNet                                               [6, 256, 200, 200]        --\n",
       "├─Sequential: 1-1                                  [6, 1, 128]               --\n",
       "│    └─PositionalEncoding: 2-1                     [6, 1, 128]               --\n",
       "│    └─Linear: 2-2                                 [6, 1, 512]               66,048\n",
       "│    └─Swish: 2-3                                  [6, 1, 512]               --\n",
       "│    └─Linear: 2-4                                 [6, 1, 128]               65,664\n",
       "├─ModuleList: 1-2                                  --                        --\n",
       "│    └─Conv2d: 2-5                                 [6, 128, 200, 200]        589,952\n",
       "│    └─ResnetBlocWithAttn: 2-6                     [6, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-1                       [6, 128, 200, 200]        312,192\n",
       "│    └─ResnetBlocWithAttn: 2-7                     [6, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-2                       [6, 128, 200, 200]        312,192\n",
       "│    └─Downsample: 2-8                             [6, 128, 100, 100]        --\n",
       "│    │    └─Conv2d: 3-3                            [6, 128, 100, 100]        147,584\n",
       "│    └─ResnetBlocWithAttn: 2-9                     [6, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-4                       [6, 256, 100, 100]        952,064\n",
       "│    └─ResnetBlocWithAttn: 2-10                    [6, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-5                       [6, 256, 100, 100]        1,214,208\n",
       "│    └─Downsample: 2-11                            [6, 256, 50, 50]          --\n",
       "│    │    └─Conv2d: 3-6                            [6, 256, 50, 50]          590,080\n",
       "│    └─ResnetBlocWithAttn: 2-12                    [6, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-7                       [6, 512, 50, 50]          3,739,136\n",
       "│    └─ResnetBlocWithAttn: 2-13                    [6, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-8                       [6, 512, 50, 50]          4,787,712\n",
       "│    └─Downsample: 2-14                            [6, 512, 25, 25]          --\n",
       "│    │    └─Conv2d: 3-9                            [6, 512, 25, 25]          2,359,808\n",
       "│    └─ResnetBlocWithAttn: 2-15                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-10                      [6, 1024, 25, 25]         14,818,304\n",
       "│    │    └─SelfAttention: 3-11                    [6, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-16                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-12                      [6, 1024, 25, 25]         19,012,608\n",
       "│    │    └─SelfAttention: 3-13                    [6, 1024, 25, 25]         4,197,376\n",
       "├─ModuleList: 1-3                                  --                        --\n",
       "│    └─ResnetBlocWithAttn: 2-17                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-14                      [6, 1024, 25, 25]         19,012,608\n",
       "│    │    └─SelfAttention: 3-15                    [6, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-18                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-16                      [6, 1024, 25, 25]         19,012,608\n",
       "├─ModuleList: 1-4                                  --                        --\n",
       "│    └─ResnetBlocWithAttn: 2-19                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-17                      [6, 1024, 25, 25]         30,550,016\n",
       "│    │    └─SelfAttention: 3-18                    [6, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-20                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-19                      [6, 1024, 25, 25]         30,550,016\n",
       "│    │    └─SelfAttention: 3-20                    [6, 1024, 25, 25]         4,197,376\n",
       "│    └─ResnetBlocWithAttn: 2-21                    [6, 1024, 25, 25]         --\n",
       "│    │    └─ResnetBlock: 3-21                      [6, 1024, 25, 25]         25,306,112\n",
       "│    │    └─SelfAttention: 3-22                    [6, 1024, 25, 25]         4,197,376\n",
       "│    └─Upsample: 2-22                              [6, 1024, 50, 50]         --\n",
       "│    │    └─Upsample: 3-23                         [6, 1024, 50, 50]         --\n",
       "│    │    └─Conv2d: 3-24                           [6, 1024, 50, 50]         9,438,208\n",
       "│    └─ResnetBlocWithAttn: 2-23                    [6, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-25                      [6, 512, 50, 50]          10,295,296\n",
       "│    └─ResnetBlocWithAttn: 2-24                    [6, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-26                      [6, 512, 50, 50]          7,672,832\n",
       "│    └─ResnetBlocWithAttn: 2-25                    [6, 512, 50, 50]          --\n",
       "│    │    └─ResnetBlock: 3-27                      [6, 512, 50, 50]          6,361,600\n",
       "│    └─Upsample: 2-26                              [6, 512, 100, 100]        --\n",
       "│    │    └─Upsample: 3-28                         [6, 512, 100, 100]        --\n",
       "│    │    └─Conv2d: 3-29                           [6, 512, 100, 100]        2,359,808\n",
       "│    └─ResnetBlocWithAttn: 2-27                    [6, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-30                      [6, 256, 100, 100]        2,591,744\n",
       "│    └─ResnetBlocWithAttn: 2-28                    [6, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-31                      [6, 256, 100, 100]        1,935,872\n",
       "│    └─ResnetBlocWithAttn: 2-29                    [6, 256, 100, 100]        --\n",
       "│    │    └─ResnetBlock: 3-32                      [6, 256, 100, 100]        1,607,936\n",
       "│    └─Upsample: 2-30                              [6, 256, 200, 200]        --\n",
       "│    │    └─Upsample: 3-33                         [6, 256, 200, 200]        --\n",
       "│    │    └─Conv2d: 3-34                           [6, 256, 200, 200]        590,080\n",
       "│    └─ResnetBlocWithAttn: 2-31                    [6, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-35                      [6, 128, 200, 200]        656,896\n",
       "│    └─ResnetBlocWithAttn: 2-32                    [6, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-36                      [6, 128, 200, 200]        492,800\n",
       "│    └─ResnetBlocWithAttn: 2-33                    [6, 128, 200, 200]        --\n",
       "│    │    └─ResnetBlock: 3-37                      [6, 128, 200, 200]        492,800\n",
       "├─Block: 1-5                                       [6, 256, 200, 200]        --\n",
       "│    └─Sequential: 2-34                            [6, 256, 200, 200]        --\n",
       "│    │    └─GroupNorm: 3-38                        [6, 128, 200, 200]        256\n",
       "│    │    └─Swish: 3-39                            [6, 128, 200, 200]        --\n",
       "│    │    └─Identity: 3-40                         [6, 128, 200, 200]        --\n",
       "│    │    └─Conv2d: 3-41                           [6, 256, 200, 200]        295,168\n",
       "====================================================================================================\n",
       "Total params: 243,374,464\n",
       "Trainable params: 243,374,464\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 2.85\n",
       "====================================================================================================\n",
       "Input size (MB): 491.52\n",
       "Forward/backward pass size (MB): 15529.55\n",
       "Params size (MB): 973.50\n",
       "Estimated Total Size (MB): 16994.57\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(Unet, input_size=[(hyperparameters['batch_size'], model_config['in_channel'], model_config['image_size'], model_config['image_size']), (hyperparameters['batch_size'], 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb31013",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "square_size = 16\n",
    "tensor = torch.zeros(1, 1, size, size)\n",
    "start = (size - square_size) // 2\n",
    "end = start + square_size\n",
    "tensor[:, :, start:end, start:end] = 1.0\n",
    "\n",
    "samples = tensor.repeat(100, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion.set_new_noise_schedule(phase='test')\n",
    "sampled = diffusion.dpm_solver_multi_step_sampler(1, steps=50, clip_denoised=True)\n",
    "y, ret_arr = sampled\n",
    "print(y)\n",
    "print(f\"Max: {torch.amax(y)}, Min: {torch.amin(y)}\")\n",
    "plt.imshow(y.cpu().numpy()[0, 0], cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ceac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data():\n",
    "    # Load the saved data\n",
    "    dataset = BEVFeaturesDataset(root_dir='/home/mingdayang/FeatureBridgeMapping/data/bev_features', transform=None)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_splits(dataset, train_split=0.8):\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(train_split * len(dataset)), len(dataset) - int(train_split * len(dataset))])\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def make_loader(batch_size, dataset):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        # Let's check out what we've created\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "dataset = load_data()\n",
    "train_dataset, test_dataset = create_splits(dataset)\n",
    "train_loader = make_loader(hyperparameters['batch_size'], train_dataset)\n",
    "test_loader = make_loader(hyperparameters['batch_size'], test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af730afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmln9d4\u001b[0m (\u001b[33mmln9d4-tu-delft\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mingdayang/FeatureBridgeMapping/wandb/run-20260217_131236-qbg1j056</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test/runs/qbg1j056' target=\"_blank\">youthful-tree-30</a></strong> to <a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test' target=\"_blank\">https://wandb.ai/mln9d4-tu-delft/diffusion_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mln9d4-tu-delft/diffusion_test/runs/qbg1j056' target=\"_blank\">https://wandb.ai/mln9d4-tu-delft/diffusion_test/runs/qbg1j056</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:   9%|▉         | 1/11 [00:02<00:21,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8441227078437805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  18%|█▊        | 2/11 [00:04<00:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8360666632652283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  27%|██▋       | 3/11 [00:05<00:15,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8235496282577515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  36%|███▋      | 4/11 [00:07<00:13,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8175937533378601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  45%|████▌     | 5/11 [00:09<00:11,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8118245601654053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8065184950828552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8035463690757751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  73%|███████▎  | 8/11 [00:15<00:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8023022413253784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  82%|████████▏ | 9/11 [00:17<00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8011170625686646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:  91%|█████████ | 10/11 [00:20<00:02,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8000731468200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████| 11/11 [00:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7993554472923279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:   9%|▉         | 1/11 [00:01<00:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7987856268882751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  18%|█▊        | 2/11 [00:03<00:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7984997630119324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  27%|██▋       | 3/11 [00:05<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7984712719917297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  36%|███▋      | 4/11 [00:07<00:13,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7982845306396484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  45%|████▌     | 5/11 [00:09<00:11,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7976917028427124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.797479510307312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7973124384880066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  73%|███████▎  | 8/11 [00:14<00:05,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7970888614654541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  82%|████████▏ | 9/11 [00:18<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7966421842575073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300:  91%|█████████ | 10/11 [00:20<00:02,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7970740795135498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|██████████| 11/11 [00:22<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7967941761016846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:   9%|▉         | 1/11 [00:01<00:18,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.796898365020752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  18%|█▊        | 2/11 [00:03<00:17,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7962692975997925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  27%|██▋       | 3/11 [00:05<00:15,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7959099411964417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  36%|███▋      | 4/11 [00:07<00:13,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7960195541381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  45%|████▌     | 5/11 [00:09<00:11,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7965874075889587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.796532928943634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7959973812103271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7970651388168335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7953234910964966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300:  91%|█████████ | 10/11 [00:20<00:02,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7957515716552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|██████████| 11/11 [00:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7950561046600342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:   9%|▉         | 1/11 [00:01<00:19,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7952281832695007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  18%|█▊        | 2/11 [00:03<00:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7944297790527344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  27%|██▋       | 3/11 [00:05<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.794302225112915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7951439023017883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  45%|████▌     | 5/11 [00:09<00:11,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7937213778495789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.794418215751648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  64%|██████▎   | 7/11 [00:15<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7933404445648193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7926390767097473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7943829298019409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  91%|█████████ | 10/11 [00:21<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7937290668487549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7923153042793274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:   9%|▉         | 1/11 [00:01<00:18,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7924906611442566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  18%|█▊        | 2/11 [00:03<00:16,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7912731766700745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7920214533805847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.793274462223053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  45%|████▌     | 5/11 [00:09<00:11,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7902165651321411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  55%|█████▍    | 6/11 [00:13<00:13,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7904682159423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  64%|██████▎   | 7/11 [00:15<00:09,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7896623611450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7902094125747681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7881224155426025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300:  91%|█████████ | 10/11 [00:21<00:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7874919176101685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7898820638656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:   9%|▉         | 1/11 [00:01<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7864083647727966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  18%|█▊        | 2/11 [00:03<00:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7863025069236755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7857045531272888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  36%|███▋      | 4/11 [00:07<00:13,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.786055326461792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  45%|████▌     | 5/11 [00:11<00:16,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7828835844993591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  55%|█████▍    | 6/11 [00:13<00:12,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.783279299736023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  64%|██████▎   | 7/11 [00:15<00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7823695540428162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7796109318733215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7772848606109619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300:  91%|█████████ | 10/11 [00:21<00:02,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7803148031234741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7775654196739197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:   9%|▉         | 1/11 [00:01<00:19,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7787734270095825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  18%|█▊        | 2/11 [00:03<00:17,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7769889235496521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  27%|██▋       | 3/11 [00:05<00:15,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7741247415542603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  36%|███▋      | 4/11 [00:09<00:18,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7732566595077515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  45%|████▌     | 5/11 [00:11<00:14,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.778141975402832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  55%|█████▍    | 6/11 [00:13<00:11,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7739723324775696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.770585834980011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7681195139884949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7769440412521362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300:  91%|█████████ | 10/11 [00:21<00:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.765667736530304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300: 100%|██████████| 11/11 [00:22<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7651867866516113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:   9%|▉         | 1/11 [00:01<00:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7700921893119812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  18%|█▊        | 2/11 [00:03<00:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7636364698410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  27%|██▋       | 3/11 [00:08<00:23,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7721006870269775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  36%|███▋      | 4/11 [00:10<00:18,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7659868597984314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  45%|████▌     | 5/11 [00:11<00:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.759876012802124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7772618532180786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.773729681968689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7673633098602295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7566608190536499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300:  91%|█████████ | 10/11 [00:21<00:02,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7590855360031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300: 100%|██████████| 11/11 [00:23<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7674962878227234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:   9%|▉         | 1/11 [00:01<00:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7566249370574951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7626208662986755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  27%|██▋       | 3/11 [00:08<00:21,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7545785307884216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  36%|███▋      | 4/11 [00:10<00:16,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7577865719795227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  45%|████▌     | 5/11 [00:11<00:13,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.750921368598938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7588316202163696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7528528571128845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  73%|███████▎  | 8/11 [00:17<00:05,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7548947930335999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  82%|████████▏ | 9/11 [00:19<00:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7560904026031494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300:  91%|█████████ | 10/11 [00:21<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.753282368183136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7482677698135376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:   9%|▉         | 1/11 [00:03<00:37,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7634565234184265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  18%|█▊        | 2/11 [00:05<00:24,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7477062344551086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  27%|██▋       | 3/11 [00:07<00:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7437124848365784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  36%|███▋      | 4/11 [00:09<00:15,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7516869902610779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  45%|████▌     | 5/11 [00:11<00:12,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7434467673301697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  55%|█████▍    | 6/11 [00:13<00:09,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7491068840026855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  64%|██████▎   | 7/11 [00:15<00:07,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.747697114944458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  73%|███████▎  | 8/11 [00:17<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7410244345664978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  82%|████████▏ | 9/11 [00:18<00:03,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7403913140296936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300:  91%|█████████ | 10/11 [00:20<00:01,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.748776912689209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.740047037601471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:   9%|▉         | 1/11 [00:01<00:18,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7390502691268921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  18%|█▊        | 2/11 [00:03<00:17,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7471584677696228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  27%|██▋       | 3/11 [00:05<00:15,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7475237250328064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7471215128898621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  45%|████▌     | 5/11 [00:09<00:11,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7548812627792358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7377633452415466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7387232780456543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  73%|███████▎  | 8/11 [00:15<00:05,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7351105809211731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  82%|████████▏ | 9/11 [00:17<00:03,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.737082839012146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300:  91%|█████████ | 10/11 [00:21<00:02,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7460026144981384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7400280833244324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:   9%|▉         | 1/11 [00:01<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7423542141914368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  18%|█▊        | 2/11 [00:03<00:17,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7399508953094482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7402819991111755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  36%|███▋      | 4/11 [00:07<00:13,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7449744939804077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  45%|████▌     | 5/11 [00:09<00:11,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7430785298347473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7369444370269775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7312026023864746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  73%|███████▎  | 8/11 [00:15<00:05,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7300217747688293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  82%|████████▏ | 9/11 [00:19<00:05,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7430335879325867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300:  91%|█████████ | 10/11 [00:21<00:02,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7342144250869751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300: 100%|██████████| 11/11 [00:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7294101119041443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:   9%|▉         | 1/11 [00:01<00:19,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.739787757396698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  18%|█▊        | 2/11 [00:03<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7302761077880859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  27%|██▋       | 3/11 [00:05<00:15,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7332197427749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  36%|███▋      | 4/11 [00:07<00:13,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7367726564407349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  45%|████▌     | 5/11 [00:09<00:11,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7410221695899963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7465898394584656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  64%|██████▎   | 7/11 [00:13<00:07,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7376255393028259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358484268188477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.747573971748352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300:  91%|█████████ | 10/11 [00:21<00:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358379364013672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300: 100%|██████████| 11/11 [00:22<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7365199327468872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:   9%|▉         | 1/11 [00:02<00:20,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.743800938129425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  18%|█▊        | 2/11 [00:03<00:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7272002100944519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  27%|██▋       | 3/11 [00:05<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.740547776222229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  36%|███▋      | 4/11 [00:07<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7315204739570618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  45%|████▌     | 5/11 [00:09<00:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7431174516677856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  55%|█████▍    | 6/11 [00:11<00:09,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7307971715927124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  64%|██████▎   | 7/11 [00:15<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7271736860275269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  73%|███████▎  | 8/11 [00:17<00:07,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7256747484207153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7245981693267822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300:  91%|█████████ | 10/11 [00:21<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358826994895935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7303423285484314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:   9%|▉         | 1/11 [00:01<00:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7311898469924927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  18%|█▊        | 2/11 [00:03<00:17,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7385170459747314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  27%|██▋       | 3/11 [00:05<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7260569334030151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  36%|███▋      | 4/11 [00:07<00:13,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7328760027885437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  45%|████▌     | 5/11 [00:09<00:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7343663573265076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  55%|█████▍    | 6/11 [00:13<00:12,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7358404994010925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  64%|██████▎   | 7/11 [00:15<00:09,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7243000268936157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7285226583480835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7240411639213562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300:  91%|█████████ | 10/11 [00:21<00:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7221397161483765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300: 100%|██████████| 11/11 [00:22<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7195029854774475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:   9%|▉         | 1/11 [00:01<00:19,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7199113965034485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  18%|█▊        | 2/11 [00:03<00:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7204291820526123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  27%|██▋       | 3/11 [00:05<00:14,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7197888493537903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  36%|███▋      | 4/11 [00:07<00:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7212901711463928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  45%|████▌     | 5/11 [00:11<00:15,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7377653121948242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  55%|█████▍    | 6/11 [00:13<00:11,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7194247245788574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7220149040222168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7208381295204163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  82%|████████▏ | 9/11 [00:19<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.72283935546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300:  91%|█████████ | 10/11 [00:20<00:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7423010468482971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7186816930770874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:   9%|▉         | 1/11 [00:01<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7267043590545654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  18%|█▊        | 2/11 [00:03<00:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7212738394737244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  27%|██▋       | 3/11 [00:05<00:15,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7296324372291565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  36%|███▋      | 4/11 [00:09<00:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7213701605796814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  45%|████▌     | 5/11 [00:11<00:14,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7157129049301147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7158142924308777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7244541049003601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7200593948364258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  82%|████████▏ | 9/11 [00:18<00:03,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7150096893310547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300:  91%|█████████ | 10/11 [00:20<00:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7274829745292664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7328810095787048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:   9%|▉         | 1/11 [00:01<00:19,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7266672253608704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  18%|█▊        | 2/11 [00:03<00:17,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7179184556007385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  27%|██▋       | 3/11 [00:08<00:23,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7231310606002808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  36%|███▋      | 4/11 [00:09<00:17,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7144427299499512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  45%|████▌     | 5/11 [00:11<00:13,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7198529839515686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7142902612686157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7144299745559692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  73%|███████▎  | 8/11 [00:17<00:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7257034182548523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  82%|████████▏ | 9/11 [00:19<00:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7109796404838562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300:  91%|█████████ | 10/11 [00:21<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7126175761222839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.712571382522583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:   9%|▉         | 1/11 [00:01<00:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.713473379611969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  18%|█▊        | 2/11 [00:05<00:27,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7211145758628845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  27%|██▋       | 3/11 [00:07<00:20,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7124940156936646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  36%|███▋      | 4/11 [00:09<00:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7212578058242798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  45%|████▌     | 5/11 [00:11<00:12,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7241895794868469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  55%|█████▍    | 6/11 [00:13<00:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7288814783096313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  64%|██████▎   | 7/11 [00:15<00:08,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7109537720680237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  73%|███████▎  | 8/11 [00:17<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7107380032539368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  82%|████████▏ | 9/11 [00:19<00:03,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7103511095046997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300:  91%|█████████ | 10/11 [00:20<00:01,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7137489914894104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7150452733039856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/300:   0%|          | 0/11 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2964214/603521227.py\", line 20, in <module>\n",
      "    loss = diffusion.forward(y0=y, y_cond=X)\n",
      "  File \"/tmp/ipykernel_2964214/913358632.py\", line 133, in forward\n",
      "    noise_hat = self.eps_model(torch.cat([y_noisy, y_cond], dim=1) if y_cond is not None else y_noisy, sample_gammas)\n",
      "  File \"/home/mingdayang/miniconda3/envs/unibev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1123, in _call_impl\n",
      "    hook_result = hook(self, input, result)\n",
      "  File \"/home/mingdayang/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\", line 114, in <lambda>\n",
      "    mod, inp, outp, log_track_params\n",
      "  File \"/home/mingdayang/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\", line 108, in parameter_log_hook\n",
      "    self.log_tensor_stats(data.cpu(), \"parameters/\" + prefix + name)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2964214/603521227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2964214/913358632.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y0, y_cond)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mnoise_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_cond\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_gammas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(mod, inp, outp)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 lambda mod, inp, outp: parameter_log_hook(\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 )\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36mparameter_log_hook\u001b[0;34m(module, input_, output, log_track)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2964214/603521227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m   3672\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3673\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexception_raised\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_finish\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"finishing run {self._get_path()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mtel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0;31m# Pop this run (hopefully) from the run stack, to support the \"reinit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/telemetry.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exctype, excinst, exctb)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_telemetry_callback\u001b[0;34m(self, telem_obj)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelem_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_telemetry_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_telemetry_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_flushed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_telemetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_flushed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_telemetry\u001b[0;34m(self, telem)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_telemetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTelemetryRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelemetry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtelem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_job_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJobInputRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMailboxHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x72415c0d95d0>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#  noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unibev/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# simple training loop using the existing `tensor` as toy data\n",
    "device = 'cuda'\n",
    "diffusion.to(device)\n",
    "diffusion.eps_model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(diffusion.eps_model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 300\n",
    "val_interval = 10\n",
    "\n",
    "with wandb.init(project=\"diffusion_test\", config=hyperparameters):\n",
    "    wandb.watch(diffusion.eps_model, log=\"all\", log_freq=10)\n",
    "    for epoch in range(epochs):\n",
    "        diffusion.set_new_noise_schedule(phase='train')\n",
    "        train_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            X, y = batch['img_bev_embed'], batch['pts_bev_embed']\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = diffusion.forward(y0=y, y_cond=X)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"Batch Loss: {loss.item()}\")\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        wandb.log({'train_loss': avg_train_loss}, step=epoch)\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ae35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3590a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdc628",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoints/diffusion_model_square.pth')\n",
    "\n",
    "Unet=UNet(**checkpoint['model_config'])\n",
    "Unet.load_state_dict(checkpoint['model_state_dict'])\n",
    "diffusion = DenoiseDiffusion(Unet, checkpoint['beta_schedule'], 'cuda:0')\n",
    "\n",
    "diffusion.set_new_noise_schedule(phase='test')\n",
    "print(diffusion.eps_model.in_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diffusion.set_new_noise_schedule(phase='test')\n",
    "y_ddpm, _ = diffusion.ddpm_sampler(1)\n",
    "y_ddim, _ = diffusion.ddim_sampler(1, steps=10, eta=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09905bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "y, _ = diffusion.ddim_sampler(1, steps=30, clip_denoised=True)\n",
    "end = time.time()\n",
    "print(y)\n",
    "print(f\"Max: {torch.amax(y)}, Min: {torch.amin(y)}\")\n",
    "print(f\"Execution time: {end - start}\")\n",
    "plt.imshow(y.cpu().numpy()[0, 0], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db89271",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "y, _ = diffusion.ddim_sampler(1, steps=50, clip_denoised=True)\n",
    "end = time.time()\n",
    "print(y)\n",
    "print(f\"Max: {torch.amax(y)}, Min: {torch.amin(y)}\")\n",
    "print(f\"Execution time: {end - start}\")\n",
    "plt.imshow(y.cpu().numpy()[0, 0], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ddpm, _ = diffusion.ddpm_sampler(1)\n",
    "y_ddim, _ = diffusion.ddim_sampler(1, steps=10)\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "im0 = ax[0].imshow(y_ddpm.cpu().numpy()[0, 0], cmap='viridis')\n",
    "im1 = ax[1].imshow(y_ddim.cpu().numpy()[0, 0], cmap='viridis')\n",
    "\n",
    "fig.colorbar(im0, ax=ax[0])\n",
    "fig.colorbar(im1, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_config, beta_schedule):\n",
    "    save_temp = {}\n",
    "    save_temp['model_state_dict'] = model.eps_model.state_dict()\n",
    "    save_temp['model_config'] = model_config\n",
    "    save_temp['beta_schedule'] = beta_schedule\n",
    "    torch.save(save_temp, 'checkpoints/temp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8190c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unibev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
